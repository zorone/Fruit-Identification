{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f92-4Hjy7kA8"
      },
      "source": [
        "<a href=\"https://www.arduino.cc/\"><img src=\"https://raw.githubusercontent.com/sandeepmistry/aimldevfest-workshop-2019/master/images/Arduino_logo_R_highquality.png\" width=200/></a>\n",
        "# Tiny ML on Arduino\n",
        "## Classify objects by color tutorial\n",
        "\n",
        "\n",
        "https://github.com/arduino/ArduinoTensorFlowLiteTutorials/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvDA8AK7QOq-"
      },
      "source": [
        "## Setup Python Environment\n",
        "\n",
        "The next cell sets up the dependencies in required for the notebook, run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2gs-PL4xDkZ",
        "outputId": "41c9efc7-5850-46cb-83d5-85eb3705922a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Setup environment\n",
        "!apt-get -qq install xxd\n",
        "!pip install pandas numpy matplotlib\n",
        "%tensorflow_version 2.x\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lwkeshJk7dg"
      },
      "source": [
        "# Upload Data\n",
        "\n",
        "1. Open the panel on the left side of Colab by clicking on the __>__\n",
        "1. Select the Files tab\n",
        "1. Drag `csv` files from your computer to the tab to upload them into colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSxUeYPNQbOg"
      },
      "source": [
        "# Train Neural Network\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxk414PU3oy3"
      },
      "source": [
        "## Parse and prepare the data\n",
        "\n",
        "The next cell parses the csv files and transforms them to a format that will be used to train the full connected neural network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AGChd1FAk5_j",
        "outputId": "abfe1a96-46ea-4a1e-caf9-b3d9b069a0a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version = 2.15.0\n",
            "\n",
            "\u001b[32;4mapple\u001b[0m class will be output \u001b[32m0\u001b[0m of the classifier\n",
            "217 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;4mbanana\u001b[0m class will be output \u001b[32m1\u001b[0m of the classifier\n",
            "217 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;4mgreen apple\u001b[0m class will be output \u001b[32m2\u001b[0m of the classifier\n",
            "217 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;4mkiwi\u001b[0m class will be output \u001b[32m3\u001b[0m of the classifier\n",
            "217 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAB+CAYAAADskGRTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAWvElEQVR4nO3da2wU1/3/8c/Y2Gtcsphg7LWJuaQhoRRibsXd9FelVSwM4h9B2wcEIUFRQpQUpBKnaeWqhaZ94LZRSHpxQ6uKulV/TQhSIWqSUrkmBqU4UG5KIA3/0DoYGtbmEl8xvuyc3wPs9e56Z71rsA3D+yWt5J0558z3zPnOjL8sLJYxxggAAAAAXCRltAMAAAAAgBuNQgcAAACA61DoAAAAAHAdCh0AAAAArkOhAwAAAMB1KHQAAAAAuA6FDgAAAADXodABAAAA4DoUOgAAAABch0IHAAAAgOskXejs379fDz/8sPLz82VZlnbv3j1on5qaGs2fP18ej0f33HOPKisrhxAqAAAAACQm6UKnvb1dhYWFqqioSKh9XV2dli1bpi9/+cs6fvy4Nm3apMcee0x/+9vfkg4WAAAAABJhGWPMkDtblnbt2qUVK1Y4tvnOd76jN954QydOnAhte+SRR9TU1KQ9e/YM9dAAAAAA4GjMcB+gtrZWxcXFEdtKSkq0adMmxz6dnZ3q7OwMvbdtW5cvX9bEiRNlWdZwhQoAAADgJmeMUWtrq/Lz85WS4vwX1Ia90AkEAsrNzY3Ylpubq5aWFnV0dGjs2LED+pSXl+vZZ58d7tAAAAAA3KLOnj2ru+66y3H/sBc6Q1FWVqbS0tLQ++bmZk2ZMkVnz56V1+sduUC6gtL/vtv7xpay6mO3M5bUPLW3mS01hrezpQkXrv1oWVJOTv/PU6eGWgVTpP9fmCFJSukO6r7XP3QIKkXSvb3HNVJzZ//m+6OaZlwbT51d0guvOM/TSWbYubaNdO5s2Nh3JDCAka62JX/ciLHjjOHUzkjqynIe3xMrh4yks5GbQuMPMo947RI6T6MlKl7HWB3mb1lSQUH/e9tIF5v6349L7e1upHbbOYyrE/qPk9GU+L5Y7SxJfSFFx2NJmtTbzpZ0znm4hFiSJrb0j3e5L6/izCO8T8Ln5QaIOC9ynnt4u7hth7AeUtR9JHpnnPEdz0WcOIZ0/mLcBwYVbx7XKe56hM09PLd7d6mjL88sqX1KWLtPYreLOK4l5UyJPO6FYIwAjZTZGjWet/9YOamx52Ub6UL9wPhkpHEOz1mp/5kU79qOnlP0c6yvX7w+4QZcp2H3Q0vSxKzE+o1zOhfqv3eEr3e8mMLXJ/xcSlHnMyKggec2M8az0JbUFLUtI+zeFr7eTv0sSXEu2VCOyJb0cex4nNYx3nmxjXS5uT+G8LVxut9GXztOORLrWLHaxctNp/7StTW9e3rvPluq+2jgduna/NvCruGhyAo/z0ZqDlvTO8KekeHXvCUpLywGOyqfJ4T9HjSh7/pIlXL+J/G4/t+9UprDdRJDS0uLCgoKdMcd8X/PGvZCx+fzqaGhIWJbQ0ODvF5vzE9zJMnj8cjj8QzY7vV6R77QGTuu940tZWbGbmcsqau3nW1LGeHtbKlvnpbVP4ZlSePGhVoFU6Rx3v5Cx+t0LKVI6u1njNSVNmBzSF+hk9YlpQ08n4NKzwibhi2NSe9/n5Y+sH00YyL7JCp87HhjOLUzkuw48x2TEWOjLSnqOH3jDzaPeO0SOU+jJTpep1id5m9ZA3MkfIy0Mf3902L9kqRr105oPaL6x9vnNIal/mWMjic8XlvXf/ezTP91ZSuxeYT3Sfi83AAR50XOcw9vF7ftENZDirqPWJKc5hg2ftxz4RDHkM9fjPvAoOLN4zrFXY+wuUdfi8ZIPX15Zklpfc8g49wu4riWlB72fLadctVI6d0Rb9UTvvYOiWbbYddBWHyy4z+rQtdvnGs7ek5O96h4fSKmGDX38PuhJed4o/ulOZ0Lxb5e4sUUvj521DmLOJ9RB4qONT1G3tqS0qK2pfW1i1pvp37ReRsuPEdkS3JYK6d1jHde7Dhr43S/jfcci94XcSyHdvFy06m/JFkpYWsaDBs7JfJaNMY5pkR5os5z+JqGYog6X5b6l8pICkblsyfsHjO2t5+VKmVG/2Iah9ebVKETCm2Qf9Iy7P+Pjt/vV3V1dcS2qqoq+f3+4T40AAAAgNtU0oVOW1ubjh8/ruPHj0u69vXRx48fV339tY9Ey8rKtGbNmlD7J554Qv/5z3/07W9/Wx988IF+9atf6dVXX9VTTz11Y2YAAAAAAFGSLnQOHz6sefPmad68eZKk0tJSzZs3T5s3b5YknT9/PlT0SNL06dP1xhtvqKqqSoWFhXr++ef129/+ViUlJTdoCgAAAAAQKem/pf6lL31J8f7rncrKyph9jh07luyhAAAAAGBIhv3f6AAAAADASKPQAQAAAOA6FDoAAAAAXIdCBwAAAIDrUOgAAAAAcB0KHQAAAACuQ6EDAAAAwHUodAAAAAC4DoUOAAAAANeh0AEAAADgOhQ6AAAAAFyHQgcAAACA61DoAAAAAHAdCh0AAAAArkOhAwAAAMB1KHQAAAAAuA6FDgAAAADXodABAAAA4DoUOgAAAABch0IHAAAAgOtQ6AAAAABwHQodAAAAAK5DoQMAAADAdSh0AAAAALgOhQ4AAAAA16HQAQAAAOA6FDoAAAAAXIdCBwAAAIDrDKnQqaio0LRp05SRkaGioiIdOnTIsW1lZaUsy4p4ZWRkDDlgAAAAABhM0oXOjh07VFpaqi1btujo0aMqLCxUSUmJGhsbHft4vV6dP38+9Dpz5sx1BQ0AAAAA8SRd6GzdulXr16/XunXrNGvWLG3btk2ZmZnavn27Yx/LsuTz+UKv3Nzc6woaAAAAAOJJqtDp6urSkSNHVFxc3D9ASoqKi4tVW1vr2K+trU1Tp05VQUGBli9frpMnT8Y9Tmdnp1paWiJeAAAAAJCopAqdixcvKhgMDvhEJjc3V4FAIGaf++67T9u3b9drr72mP/7xj7JtWw888IDOnTvneJzy8nKNHz8+9CooKEgmTAAAAAC3uWH/1jW/3681a9Zo7ty5evDBB/XnP/9ZkyZN0q9//WvHPmVlZWpubg69zp49O9xhAgAAAHCRMck0zs7OVmpqqhoaGiK2NzQ0yOfzJTRGWlqa5s2bp9OnTzu28Xg88ng8yYQGAAAAACFJfaKTnp6uBQsWqLq6OrTNtm1VV1fL7/cnNEYwGNR7772nvLy85CIFAAAAgAQl9YmOJJWWlmrt2rVauHChFi1apBdffFHt7e1at26dJGnNmjWaPHmyysvLJUk//OEP9fnPf1733HOPmpqa9Nxzz+nMmTN67LHHbuxMAAAAAKBX0oXOypUrdeHCBW3evFmBQEBz587Vnj17Ql9QUF9fr5SU/g+KPvnkE61fv16BQEATJkzQggULdODAAc2aNevGzQIAAAAAwiRd6EjSxo0btXHjxpj7ampqIt6/8MILeuGFF4ZyGAAAAAAYkmH/1jUAAAAAGGkUOgAAAABch0IHAAAAgOtQ6AAAAABwHQodAAAAAK5DoQMAAADAdSh0AAAAALgOhQ4AAAAA16HQAQAAAOA6FDoAAAAAXIdCBwAAAIDrUOgAAAAAcB0KHQAAAACuQ6EDAAAAwHUodAAAAAC4DoUOAAAAANeh0AEAAADgOhQ6AAAAAFyHQgcAAACA61DoAAAAAHAdCh0AAAAArkOhAwAAAMB1KHQAAAAAuA6FDgAAAADXodABAAAA4DoUOgAAAABch0IHAAAAgOsMqdCpqKjQtGnTlJGRoaKiIh06dChu+507d2rmzJnKyMjQnDlz9Oabbw4pWAAAAABIRNKFzo4dO1RaWqotW7bo6NGjKiwsVElJiRobG2O2P3DggFatWqVHH31Ux44d04oVK7RixQqdOHHiuoMHAAAAgFiSLnS2bt2q9evXa926dZo1a5a2bdumzMxMbd++PWb7n/3sZ1qyZImeeeYZfeYzn9GPfvQjzZ8/X7/85S+vO3gAAAAAiGVMMo27urp05MgRlZWVhbalpKSouLhYtbW1MfvU1taqtLQ0YltJSYl2797teJzOzk51dnaG3jc3N0uSWlpakgn3+nUFpY623je25LkSu52x+tvZtnQ1vJ0tdXRc+9GypCtX+n9uawu1CqZIbS09kqSU7qBarjgcSymSevsZI3V0Dtgc0nNtPHV2Sd2dSlrX1bBpGKmnq/99d9fA9gNE9UlUxNhxxnBqZyT1xJlv6tUYG42kqOOExh9kHvHaJXSeRkuia+owf8samCPhY3QHe7sbqdt2DqOnbwwzMIZ4+2K1s9S/jNHxWOqP15bU4zxcQiz1X1f2ILGGx9fXJ+HzcgNEnBc5zz28Xdy2Q1gPKeo+YklymmPU+I7nIk4cQzp/Me4Dg4o3j+sUdz3C5h6e2727+vPMkro7Bm8XcVxL6uqIPG7f9RzBxBgvPexYqbHnZZvY8cnEf1aFrt8413b0nJzuUfH6hBtwnYblcPj1PFi/mOdPkfeO8PWOF1P4+thR5yzifEYENHC8rhh5a0vqjtqWmt4/Rqw+0f2i8zYqjFCOyJbksFZO6xjvvNhx1sbpfht9TTjlSKxjxWoXLzed+ktRa2qHjR11LZo4MSWqM73/ZxO1pqEYFJmzlvqXykiyo67tzjH9O0O/86ZKV6J/MY2jpUVKc7hnxGx+rSYwxsRtl1Shc/HiRQWDQeXm5kZsz83N1QcffBCzTyAQiNk+EAg4Hqe8vFzPPvvsgO0FBQXJhAsAAADApVpbWzV+/HjH/UkVOiOlrKws4lMg27Z1+fJlTZw4UZZljWJk1yrIgoICnT17Vl6vd1RjAcKRm7hZkZu4WZGbuFmRm/EZY9Ta2qr8/Py47ZIqdLKzs5WamqqGhoaI7Q0NDfL5fDH7+Hy+pNpLksfjkcfjidiWlZWVTKjDzuv1kni4KZGbuFmRm7hZkZu4WZGbzuJ9ktMnqS8jSE9P14IFC1RdXR3aZtu2qqur5ff7Y/bx+/0R7SWpqqrKsT0AAAAAXK+k/+paaWmp1q5dq4ULF2rRokV68cUX1d7ernXr1kmS1qxZo8mTJ6u8vFyS9M1vflMPPvignn/+eS1btkyvvPKKDh8+rN/85jc3diYAAAAA0CvpQmflypW6cOGCNm/erEAgoLlz52rPnj2hLxyor69XSkr/B0UPPPCA/vSnP+l73/uevvvd72rGjBnavXu3Zs+efeNmMYI8Ho+2bNky4K/WAaON3MTNitzEzYrcxM2K3LwxLDPY97IBAAAAwC0m6f8wFAAAAABudhQ6AAAAAFyHQgcAAACA61DoAAAAAHAdCp0kVFRUaNq0acrIyFBRUZEOHTo02iHhNvODH/xAlmVFvGbOnBnaf/XqVW3YsEETJ07UuHHj9LWvfW3Af9gL3Aj79+/Xww8/rPz8fFmWpd27d0fsN8Zo8+bNysvL09ixY1VcXKwPP/wwos3ly5e1evVqeb1eZWVl6dFHH1VbW9sIzgJuNFhufv3rXx9wH12yZElEG3ITw6G8vFyf+9zndMcddygnJ0crVqzQqVOnItok8hyvr6/XsmXLlJmZqZycHD3zzDPq6ekZyancMih0ErRjxw6VlpZqy5YtOnr0qAoLC1VSUqLGxsbRDg23mc9+9rM6f/586PX222+H9j311FP6y1/+op07d2rfvn36+OOP9dWvfnUUo4Vbtbe3q7CwUBUVFTH3//SnP9XPf/5zbdu2TQcPHtSnPvUplZSU6OrVq6E2q1ev1smTJ1VVVaXXX39d+/fv1+OPPz5SU4BLDZabkrRkyZKI++jLL78csZ/cxHDYt2+fNmzYoHfeeUdVVVXq7u7W4sWL1d7eHmoz2HM8GAxq2bJl6urq0oEDB/T73/9elZWV2rx582hM6eZnkJBFixaZDRs2hN4Hg0GTn59vysvLRzEq3G62bNliCgsLY+5ramoyaWlpZufOnaFt//rXv4wkU1tbO0IR4nYkyezatSv03rZt4/P5zHPPPRfa1tTUZDwej3n55ZeNMca8//77RpL55z//GWrz17/+1ViWZf773/+OWOxwt+jcNMaYtWvXmuXLlzv2ITcxUhobG40ks2/fPmNMYs/xN99806SkpJhAIBBq89JLLxmv12s6OztHdgK3AD7RSUBXV5eOHDmi4uLi0LaUlBQVFxertrZ2FCPD7ejDDz9Ufn6+7r77bq1evVr19fWSpCNHjqi7uzsiT2fOnKkpU6aQpxhRdXV1CgQCEbk4fvx4FRUVhXKxtrZWWVlZWrhwYahNcXGxUlJSdPDgwRGPGbeXmpoa5eTk6L777tOTTz6pS5cuhfaRmxgpzc3NkqQ777xTUmLP8draWs2ZM0e5ubmhNiUlJWppadHJkydHMPpbA4VOAi5evKhgMBiRVJKUm5urQCAwSlHhdlRUVKTKykrt2bNHL730kurq6vTFL35Rra2tCgQCSk9PV1ZWVkQf8hQjrS/f4t0zA4GAcnJyIvaPGTNGd955J/mKYbVkyRL94Q9/UHV1tX7yk59o3759Wrp0qYLBoCRyEyPDtm1t2rRJX/jCFzR79mxJSug5HggEYt5b+/Yh0pjRDgBA4pYuXRr6+f7771dRUZGmTp2qV199VWPHjh3FyADg1vDII4+Efp4zZ47uv/9+ffrTn1ZNTY0eeuihUYwMt5MNGzboxIkTEf/OFjcen+gkIDs7W6mpqQO+9aKhoUE+n2+UogKkrKws3XvvvTp9+rR8Pp+6urrU1NQU0YY8xUjry7d490yfzzfgy1x6enp0+fJl8hUj6u6771Z2drZOnz4tidzE8Nu4caNef/11vfXWW7rrrrtC2xN5jvt8vpj31r59iEShk4D09HQtWLBA1dXVoW22bau6ulp+v38UI8Ptrq2tTf/+97+Vl5enBQsWKC0tLSJPT506pfr6evIUI2r69Ony+XwRudjS0qKDBw+GctHv96upqUlHjhwJtdm7d69s21ZRUdGIx4zb17lz53Tp0iXl5eVJIjcxfIwx2rhxo3bt2qW9e/dq+vTpEfsTeY77/X699957EcV4VVWVvF6vZs2aNTITuZWM9rch3CpeeeUV4/F4TGVlpXn//ffN448/brKysiK+9QIYbk8//bSpqakxdXV15h//+IcpLi422dnZprGx0RhjzBNPPGGmTJli9u7daw4fPmz8fr/x+/2jHDXcqLW11Rw7dswcO3bMSDJbt241x44dM2fOnDHGGPPjH//YZGVlmddee828++67Zvny5Wb69Ommo6MjNMaSJUvMvHnzzMGDB83bb79tZsyYYVatWjVaU4JLxMvN1tZW861vfcvU1taauro68/e//93Mnz/fzJgxw1y9ejU0BrmJ4fDkk0+a8ePHm5qaGnP+/PnQ68qVK6E2gz3He3p6zOzZs83ixYvN8ePHzZ49e8ykSZNMWVnZaEzppkehk4Rf/OIXZsqUKSY9Pd0sWrTIvPPOO6MdEm4zK1euNHl5eSY9Pd1MnjzZrFy50pw+fTq0v6Ojw3zjG98wEyZMMJmZmeYrX/mKOX/+/ChGDLd66623jKQBr7Vr1xpjrn3F9Pe//32Tm5trPB6Peeihh8ypU6cixrh06ZJZtWqVGTdunPF6vWbdunWmtbV1FGYDN4mXm1euXDGLFy82kyZNMmlpaWbq1Klm/fr1A/7QktzEcIiVl5LM7373u1CbRJ7jH330kVm6dKkZO3asyc7ONk8//bTp7u4e4dncGixjjBnpT5EAAAAAYDjxb3QAAAAAuA6FDgAAAADXodABAAAA4DoUOgAAAABch0IHAAAAgOtQ6AAAAABwHQodAAAAAK5DoQMAAADAdSh0AAAAALgOhQ4AAAAA16HQAQAAAOA6FDoAAAAAXOf/AGlYmIlyWugXAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;4mmangosteen\u001b[0m class will be output \u001b[32m4\u001b[0m of the classifier\n",
            "217 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;4morange\u001b[0m class will be output \u001b[32m5\u001b[0m of the classifier\n",
            "123 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;4mtrolley\u001b[0m class will be output \u001b[32m6\u001b[0m of the classifier\n",
            "123 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data set parsing and preparation complete.\n",
            "Data set randomization and splitting complete.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import fileinput\n",
        "\n",
        "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
        "\n",
        "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
        "# the same random numbers each time the notebook is run\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "CLASSES = [];\n",
        "\n",
        "for file in os.listdir(\"/content/\"):\n",
        "    if file.endswith(\".csv\"):\n",
        "        CLASSES.append(os.path.splitext(file)[0])\n",
        "\n",
        "CLASSES.sort()\n",
        "\n",
        "SAMPLES_WINDOW_LEN = 1\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "# create a one-hot encoded matrix that is used in the output\n",
        "ONE_HOT_ENCODED_CLASSES = np.eye(NUM_CLASSES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# read each csv file and push an input and output\n",
        "for class_index in range(NUM_CLASSES):\n",
        "  objectClass = CLASSES[class_index]\n",
        "  df = pd.read_csv(\"/content/\" + objectClass + \".csv\")\n",
        "  columns = list(df)\n",
        "  # get rid of pesky empty value lines of csv which cause NaN inputs to TensorFlow\n",
        "  df = df.dropna()\n",
        "  df = df.reset_index(drop=True)\n",
        "\n",
        "  # calculate the number of objectClass recordings in the file\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_WINDOW_LEN)\n",
        "  print(f\"\\u001b[32;4m{objectClass}\\u001b[0m class will be output \\u001b[32m{class_index}\\u001b[0m of the classifier\")\n",
        "  print(f\"{num_recordings} samples captured for training with inputs {list(df)} \\n\")\n",
        "\n",
        "  # graphing\n",
        "  plt.rcParams[\"figure.figsize\"] = (10,1)\n",
        "  pixels = np.array([df['Red'],df['Green'],df['Blue']],float)\n",
        "  pixels = np.transpose(pixels)\n",
        "  for i in range(num_recordings):\n",
        "    plt.axvline(x=i, linewidth=8, color=tuple(pixels[i]/np.max(pixels[i], axis=0)))\n",
        "  plt.show()\n",
        "\n",
        "  #tensors\n",
        "  output = ONE_HOT_ENCODED_CLASSES[class_index]\n",
        "  for i in range(num_recordings):\n",
        "    tensor = []\n",
        "    row = []\n",
        "    for c in columns:\n",
        "      row.append(df[c][i])\n",
        "    tensor += row\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "# convert the list to numpy array\n",
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "print(\"Data set parsing and preparation complete.\")\n",
        "\n",
        "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
        "# https://stackoverflow.com/a/37710486/2020087\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "print(\"Data set randomization and splitting complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8qlSAX1b6Yv"
      },
      "source": [
        "## Build & Train the Model\n",
        "\n",
        "Build and train a [TensorFlow](https://www.tensorflow.org) model using the high-level [Keras](https://www.tensorflow.org/guide/keras) API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGNFa-lX24Qo",
        "outputId": "b02702bc-91dd-4cea-aab7-ee4b098df9b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1222 - mae: 0.2446 - val_loss: 0.1219 - val_mae: 0.2443\n",
            "Epoch 2/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1215 - mae: 0.2438 - val_loss: 0.1213 - val_mae: 0.2434\n",
            "Epoch 3/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1209 - mae: 0.2428 - val_loss: 0.1207 - val_mae: 0.2425\n",
            "Epoch 4/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1203 - mae: 0.2419 - val_loss: 0.1202 - val_mae: 0.2416\n",
            "Epoch 5/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1197 - mae: 0.2409 - val_loss: 0.1194 - val_mae: 0.2404\n",
            "Epoch 6/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1187 - mae: 0.2395 - val_loss: 0.1182 - val_mae: 0.2389\n",
            "Epoch 7/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1177 - mae: 0.2379 - val_loss: 0.1173 - val_mae: 0.2371\n",
            "Epoch 8/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1168 - mae: 0.2362 - val_loss: 0.1166 - val_mae: 0.2356\n",
            "Epoch 9/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1161 - mae: 0.2349 - val_loss: 0.1160 - val_mae: 0.2346\n",
            "Epoch 10/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1155 - mae: 0.2338 - val_loss: 0.1154 - val_mae: 0.2335\n",
            "Epoch 11/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1149 - mae: 0.2329 - val_loss: 0.1149 - val_mae: 0.2326\n",
            "Epoch 12/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1144 - mae: 0.2321 - val_loss: 0.1143 - val_mae: 0.2319\n",
            "Epoch 13/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1140 - mae: 0.2314 - val_loss: 0.1139 - val_mae: 0.2312\n",
            "Epoch 14/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1135 - mae: 0.2306 - val_loss: 0.1134 - val_mae: 0.2305\n",
            "Epoch 15/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1130 - mae: 0.2300 - val_loss: 0.1130 - val_mae: 0.2300\n",
            "Epoch 16/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1127 - mae: 0.2295 - val_loss: 0.1126 - val_mae: 0.2293\n",
            "Epoch 17/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1123 - mae: 0.2289 - val_loss: 0.1123 - val_mae: 0.2288\n",
            "Epoch 18/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1120 - mae: 0.2284 - val_loss: 0.1120 - val_mae: 0.2282\n",
            "Epoch 19/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1116 - mae: 0.2277 - val_loss: 0.1115 - val_mae: 0.2277\n",
            "Epoch 20/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1114 - mae: 0.2274 - val_loss: 0.1113 - val_mae: 0.2273\n",
            "Epoch 21/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1111 - mae: 0.2270 - val_loss: 0.1111 - val_mae: 0.2268\n",
            "Epoch 22/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1109 - mae: 0.2265 - val_loss: 0.1108 - val_mae: 0.2265\n",
            "Epoch 23/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1106 - mae: 0.2261 - val_loss: 0.1107 - val_mae: 0.2262\n",
            "Epoch 24/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1104 - mae: 0.2257 - val_loss: 0.1104 - val_mae: 0.2256\n",
            "Epoch 25/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1102 - mae: 0.2254 - val_loss: 0.1102 - val_mae: 0.2253\n",
            "Epoch 26/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1101 - mae: 0.2250 - val_loss: 0.1100 - val_mae: 0.2249\n",
            "Epoch 27/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1099 - mae: 0.2247 - val_loss: 0.1099 - val_mae: 0.2247\n",
            "Epoch 28/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1097 - mae: 0.2244 - val_loss: 0.1099 - val_mae: 0.2244\n",
            "Epoch 29/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1096 - mae: 0.2241 - val_loss: 0.1096 - val_mae: 0.2241\n",
            "Epoch 30/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1095 - mae: 0.2238 - val_loss: 0.1095 - val_mae: 0.2238\n",
            "Epoch 31/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1094 - mae: 0.2236 - val_loss: 0.1094 - val_mae: 0.2236\n",
            "Epoch 32/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1092 - mae: 0.2232 - val_loss: 0.1092 - val_mae: 0.2233\n",
            "Epoch 33/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1091 - mae: 0.2230 - val_loss: 0.1092 - val_mae: 0.2230\n",
            "Epoch 34/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1090 - mae: 0.2228 - val_loss: 0.1092 - val_mae: 0.2229\n",
            "Epoch 35/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1089 - mae: 0.2225 - val_loss: 0.1090 - val_mae: 0.2226\n",
            "Epoch 36/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1088 - mae: 0.2224 - val_loss: 0.1089 - val_mae: 0.2224\n",
            "Epoch 37/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1088 - mae: 0.2221 - val_loss: 0.1088 - val_mae: 0.2222\n",
            "Epoch 38/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1087 - mae: 0.2219 - val_loss: 0.1087 - val_mae: 0.2219\n",
            "Epoch 39/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1086 - mae: 0.2218 - val_loss: 0.1086 - val_mae: 0.2218\n",
            "Epoch 40/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1085 - mae: 0.2216 - val_loss: 0.1086 - val_mae: 0.2216\n",
            "Epoch 41/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1085 - mae: 0.2214 - val_loss: 0.1086 - val_mae: 0.2215\n",
            "Epoch 42/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1084 - mae: 0.2212 - val_loss: 0.1085 - val_mae: 0.2212\n",
            "Epoch 43/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1083 - mae: 0.2210 - val_loss: 0.1084 - val_mae: 0.2211\n",
            "Epoch 44/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1083 - mae: 0.2209 - val_loss: 0.1084 - val_mae: 0.2209\n",
            "Epoch 45/400\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.1082 - mae: 0.2207 - val_loss: 0.1082 - val_mae: 0.2207\n",
            "Epoch 46/400\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.1082 - mae: 0.2205 - val_loss: 0.1082 - val_mae: 0.2206\n",
            "Epoch 47/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1082 - mae: 0.2205 - val_loss: 0.1082 - val_mae: 0.2205\n",
            "Epoch 48/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1081 - mae: 0.2203 - val_loss: 0.1083 - val_mae: 0.2204\n",
            "Epoch 49/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1081 - mae: 0.2202 - val_loss: 0.1082 - val_mae: 0.2203\n",
            "Epoch 50/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1080 - mae: 0.2201 - val_loss: 0.1081 - val_mae: 0.2201\n",
            "Epoch 51/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1080 - mae: 0.2199 - val_loss: 0.1080 - val_mae: 0.2200\n",
            "Epoch 52/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1080 - mae: 0.2198 - val_loss: 0.1080 - val_mae: 0.2198\n",
            "Epoch 53/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1079 - mae: 0.2197 - val_loss: 0.1079 - val_mae: 0.2197\n",
            "Epoch 54/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1079 - mae: 0.2196 - val_loss: 0.1079 - val_mae: 0.2195\n",
            "Epoch 55/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1078 - mae: 0.2195 - val_loss: 0.1080 - val_mae: 0.2195\n",
            "Epoch 56/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1078 - mae: 0.2193 - val_loss: 0.1078 - val_mae: 0.2193\n",
            "Epoch 57/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1078 - mae: 0.2193 - val_loss: 0.1079 - val_mae: 0.2193\n",
            "Epoch 58/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1077 - mae: 0.2190 - val_loss: 0.1078 - val_mae: 0.2191\n",
            "Epoch 59/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1078 - mae: 0.2191 - val_loss: 0.1077 - val_mae: 0.2190\n",
            "Epoch 60/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1077 - mae: 0.2190 - val_loss: 0.1078 - val_mae: 0.2190\n",
            "Epoch 61/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1077 - mae: 0.2188 - val_loss: 0.1077 - val_mae: 0.2189\n",
            "Epoch 62/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1077 - mae: 0.2188 - val_loss: 0.1077 - val_mae: 0.2187\n",
            "Epoch 63/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1076 - mae: 0.2187 - val_loss: 0.1077 - val_mae: 0.2187\n",
            "Epoch 64/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1076 - mae: 0.2186 - val_loss: 0.1077 - val_mae: 0.2186\n",
            "Epoch 65/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1076 - mae: 0.2184 - val_loss: 0.1075 - val_mae: 0.2185\n",
            "Epoch 66/400\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1076 - mae: 0.2185 - val_loss: 0.1077 - val_mae: 0.2185\n",
            "Epoch 67/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1076 - mae: 0.2184 - val_loss: 0.1078 - val_mae: 0.2185\n",
            "Epoch 68/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1076 - mae: 0.2183 - val_loss: 0.1077 - val_mae: 0.2184\n",
            "Epoch 69/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1076 - mae: 0.2182 - val_loss: 0.1075 - val_mae: 0.2182\n",
            "Epoch 70/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1075 - mae: 0.2182 - val_loss: 0.1075 - val_mae: 0.2182\n",
            "Epoch 71/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1075 - mae: 0.2181 - val_loss: 0.1076 - val_mae: 0.2182\n",
            "Epoch 72/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1075 - mae: 0.2180 - val_loss: 0.1076 - val_mae: 0.2181\n",
            "Epoch 73/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1075 - mae: 0.2179 - val_loss: 0.1075 - val_mae: 0.2180\n",
            "Epoch 74/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1075 - mae: 0.2179 - val_loss: 0.1075 - val_mae: 0.2179\n",
            "Epoch 75/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1075 - mae: 0.2179 - val_loss: 0.1076 - val_mae: 0.2179\n",
            "Epoch 76/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1074 - mae: 0.2177 - val_loss: 0.1074 - val_mae: 0.2177\n",
            "Epoch 77/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1074 - mae: 0.2178 - val_loss: 0.1075 - val_mae: 0.2177\n",
            "Epoch 78/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1074 - mae: 0.2177 - val_loss: 0.1076 - val_mae: 0.2177\n",
            "Epoch 79/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1074 - mae: 0.2176 - val_loss: 0.1074 - val_mae: 0.2176\n",
            "Epoch 80/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1074 - mae: 0.2176 - val_loss: 0.1075 - val_mae: 0.2176\n",
            "Epoch 81/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1074 - mae: 0.2174 - val_loss: 0.1074 - val_mae: 0.2176\n",
            "Epoch 82/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1074 - mae: 0.2175 - val_loss: 0.1074 - val_mae: 0.2174\n",
            "Epoch 83/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1074 - mae: 0.2174 - val_loss: 0.1074 - val_mae: 0.2174\n",
            "Epoch 84/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1073 - mae: 0.2173 - val_loss: 0.1073 - val_mae: 0.2172\n",
            "Epoch 85/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1074 - mae: 0.2174 - val_loss: 0.1074 - val_mae: 0.2173\n",
            "Epoch 86/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1073 - mae: 0.2172 - val_loss: 0.1075 - val_mae: 0.2173\n",
            "Epoch 87/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1074 - mae: 0.2171 - val_loss: 0.1073 - val_mae: 0.2172\n",
            "Epoch 88/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1073 - mae: 0.2172 - val_loss: 0.1074 - val_mae: 0.2172\n",
            "Epoch 89/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1073 - mae: 0.2171 - val_loss: 0.1073 - val_mae: 0.2171\n",
            "Epoch 90/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1073 - mae: 0.2171 - val_loss: 0.1074 - val_mae: 0.2171\n",
            "Epoch 91/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1073 - mae: 0.2171 - val_loss: 0.1073 - val_mae: 0.2170\n",
            "Epoch 92/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1073 - mae: 0.2170 - val_loss: 0.1074 - val_mae: 0.2170\n",
            "Epoch 93/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1073 - mae: 0.2170 - val_loss: 0.1074 - val_mae: 0.2170\n",
            "Epoch 94/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1073 - mae: 0.2169 - val_loss: 0.1073 - val_mae: 0.2170\n",
            "Epoch 95/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1073 - mae: 0.2170 - val_loss: 0.1074 - val_mae: 0.2170\n",
            "Epoch 96/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1073 - mae: 0.2168 - val_loss: 0.1074 - val_mae: 0.2169\n",
            "Epoch 97/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1072 - mae: 0.2169 - val_loss: 0.1074 - val_mae: 0.2169\n",
            "Epoch 98/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1073 - mae: 0.2168 - val_loss: 0.1073 - val_mae: 0.2168\n",
            "Epoch 99/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1073 - mae: 0.2168 - val_loss: 0.1073 - val_mae: 0.2167\n",
            "Epoch 100/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1073 - mae: 0.2168 - val_loss: 0.1073 - val_mae: 0.2167\n",
            "Epoch 101/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2167 - val_loss: 0.1073 - val_mae: 0.2167\n",
            "Epoch 102/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1073 - mae: 0.2167 - val_loss: 0.1072 - val_mae: 0.2166\n",
            "Epoch 103/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2166 - val_loss: 0.1073 - val_mae: 0.2166\n",
            "Epoch 104/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1073 - mae: 0.2166 - val_loss: 0.1073 - val_mae: 0.2166\n",
            "Epoch 105/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2165 - val_loss: 0.1073 - val_mae: 0.2166\n",
            "Epoch 106/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2165 - val_loss: 0.1074 - val_mae: 0.2166\n",
            "Epoch 107/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2165 - val_loss: 0.1072 - val_mae: 0.2164\n",
            "Epoch 108/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2164 - val_loss: 0.1072 - val_mae: 0.2165\n",
            "Epoch 109/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2165 - val_loss: 0.1072 - val_mae: 0.2164\n",
            "Epoch 110/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2165 - val_loss: 0.1073 - val_mae: 0.2164\n",
            "Epoch 111/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2164 - val_loss: 0.1074 - val_mae: 0.2164\n",
            "Epoch 112/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2163 - val_loss: 0.1073 - val_mae: 0.2164\n",
            "Epoch 113/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2163 - val_loss: 0.1071 - val_mae: 0.2163\n",
            "Epoch 114/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2164 - val_loss: 0.1071 - val_mae: 0.2163\n",
            "Epoch 115/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2163 - val_loss: 0.1072 - val_mae: 0.2162\n",
            "Epoch 116/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2163 - val_loss: 0.1073 - val_mae: 0.2163\n",
            "Epoch 117/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2161 - val_loss: 0.1071 - val_mae: 0.2162\n",
            "Epoch 118/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2163 - val_loss: 0.1072 - val_mae: 0.2162\n",
            "Epoch 119/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2163 - val_loss: 0.1072 - val_mae: 0.2162\n",
            "Epoch 120/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2162 - val_loss: 0.1072 - val_mae: 0.2161\n",
            "Epoch 121/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2162 - val_loss: 0.1071 - val_mae: 0.2162\n",
            "Epoch 122/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2162 - val_loss: 0.1072 - val_mae: 0.2160\n",
            "Epoch 123/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1072 - mae: 0.2161 - val_loss: 0.1072 - val_mae: 0.2160\n",
            "Epoch 124/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2159 - val_loss: 0.1072 - val_mae: 0.2160\n",
            "Epoch 125/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1072 - mae: 0.2160 - val_loss: 0.1073 - val_mae: 0.2161\n",
            "Epoch 126/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1072 - mae: 0.2161 - val_loss: 0.1073 - val_mae: 0.2161\n",
            "Epoch 127/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1072 - mae: 0.2161 - val_loss: 0.1073 - val_mae: 0.2160\n",
            "Epoch 128/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1072 - mae: 0.2160 - val_loss: 0.1073 - val_mae: 0.2160\n",
            "Epoch 129/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1072 - mae: 0.2160 - val_loss: 0.1071 - val_mae: 0.2161\n",
            "Epoch 130/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2161 - val_loss: 0.1071 - val_mae: 0.2160\n",
            "Epoch 131/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2160 - val_loss: 0.1072 - val_mae: 0.2158\n",
            "Epoch 132/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2159 - val_loss: 0.1071 - val_mae: 0.2158\n",
            "Epoch 133/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2160 - val_loss: 0.1072 - val_mae: 0.2158\n",
            "Epoch 134/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2160 - val_loss: 0.1073 - val_mae: 0.2158\n",
            "Epoch 135/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2159 - val_loss: 0.1073 - val_mae: 0.2160\n",
            "Epoch 136/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2159 - val_loss: 0.1072 - val_mae: 0.2160\n",
            "Epoch 137/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2160 - val_loss: 0.1072 - val_mae: 0.2159\n",
            "Epoch 138/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2160 - val_loss: 0.1072 - val_mae: 0.2159\n",
            "Epoch 139/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2159 - val_loss: 0.1073 - val_mae: 0.2158\n",
            "Epoch 140/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2157 - val_loss: 0.1072 - val_mae: 0.2160\n",
            "Epoch 141/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2159 - val_loss: 0.1073 - val_mae: 0.2160\n",
            "Epoch 142/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2160 - val_loss: 0.1073 - val_mae: 0.2158\n",
            "Epoch 143/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2158 - val_loss: 0.1072 - val_mae: 0.2156\n",
            "Epoch 144/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2157 - val_loss: 0.1071 - val_mae: 0.2156\n",
            "Epoch 145/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2156 - val_loss: 0.1070 - val_mae: 0.2157\n",
            "Epoch 146/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2157 - val_loss: 0.1072 - val_mae: 0.2156\n",
            "Epoch 147/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2157 - val_loss: 0.1071 - val_mae: 0.2155\n",
            "Epoch 148/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2156 - val_loss: 0.1071 - val_mae: 0.2155\n",
            "Epoch 149/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2156 - val_loss: 0.1071 - val_mae: 0.2156\n",
            "Epoch 150/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2157 - val_loss: 0.1071 - val_mae: 0.2157\n",
            "Epoch 151/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2157 - val_loss: 0.1070 - val_mae: 0.2158\n",
            "Epoch 152/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2157 - val_loss: 0.1071 - val_mae: 0.2157\n",
            "Epoch 153/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2157 - val_loss: 0.1073 - val_mae: 0.2156\n",
            "Epoch 154/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2155 - val_loss: 0.1072 - val_mae: 0.2159\n",
            "Epoch 155/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1072 - mae: 0.2156 - val_loss: 0.1072 - val_mae: 0.2155\n",
            "Epoch 156/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2156 - val_loss: 0.1072 - val_mae: 0.2155\n",
            "Epoch 157/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2156 - val_loss: 0.1072 - val_mae: 0.2154\n",
            "Epoch 158/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2154 - val_loss: 0.1072 - val_mae: 0.2155\n",
            "Epoch 159/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2156 - val_loss: 0.1072 - val_mae: 0.2155\n",
            "Epoch 160/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2155 - val_loss: 0.1071 - val_mae: 0.2154\n",
            "Epoch 161/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2155 - val_loss: 0.1071 - val_mae: 0.2155\n",
            "Epoch 162/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2155 - val_loss: 0.1073 - val_mae: 0.2155\n",
            "Epoch 163/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2157 - val_loss: 0.1072 - val_mae: 0.2154\n",
            "Epoch 164/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2154 - val_loss: 0.1073 - val_mae: 0.2154\n",
            "Epoch 165/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2154 - val_loss: 0.1071 - val_mae: 0.2153\n",
            "Epoch 166/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2154 - val_loss: 0.1072 - val_mae: 0.2154\n",
            "Epoch 167/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2154 - val_loss: 0.1071 - val_mae: 0.2154\n",
            "Epoch 168/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2155 - val_loss: 0.1072 - val_mae: 0.2155\n",
            "Epoch 169/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2154 - val_loss: 0.1073 - val_mae: 0.2154\n",
            "Epoch 170/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2154 - val_loss: 0.1071 - val_mae: 0.2154\n",
            "Epoch 171/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2155 - val_loss: 0.1072 - val_mae: 0.2152\n",
            "Epoch 172/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2153 - val_loss: 0.1072 - val_mae: 0.2154\n",
            "Epoch 173/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2155 - val_loss: 0.1073 - val_mae: 0.2153\n",
            "Epoch 174/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2154 - val_loss: 0.1074 - val_mae: 0.2154\n",
            "Epoch 175/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2154 - val_loss: 0.1073 - val_mae: 0.2153\n",
            "Epoch 176/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2154 - val_loss: 0.1072 - val_mae: 0.2153\n",
            "Epoch 177/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2153 - val_loss: 0.1072 - val_mae: 0.2153\n",
            "Epoch 178/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1071 - val_mae: 0.2153\n",
            "Epoch 179/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2154 - val_loss: 0.1072 - val_mae: 0.2152\n",
            "Epoch 180/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1072 - val_mae: 0.2155\n",
            "Epoch 181/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2153 - val_loss: 0.1072 - val_mae: 0.2152\n",
            "Epoch 182/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1072 - mae: 0.2153 - val_loss: 0.1073 - val_mae: 0.2152\n",
            "Epoch 183/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1073 - val_mae: 0.2152\n",
            "Epoch 184/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1072 - val_mae: 0.2151\n",
            "Epoch 185/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1071 - val_mae: 0.2151\n",
            "Epoch 186/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1071 - val_mae: 0.2151\n",
            "Epoch 187/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1071 - val_mae: 0.2151\n",
            "Epoch 188/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2153\n",
            "Epoch 189/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1071 - val_mae: 0.2151\n",
            "Epoch 190/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1072 - val_mae: 0.2151\n",
            "Epoch 191/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1070 - val_mae: 0.2151\n",
            "Epoch 192/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2151\n",
            "Epoch 193/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1072 - val_mae: 0.2151\n",
            "Epoch 194/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2153 - val_loss: 0.1074 - val_mae: 0.2152\n",
            "Epoch 195/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1075 - val_mae: 0.2152\n",
            "Epoch 196/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1070 - val_mae: 0.2150\n",
            "Epoch 197/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1069 - val_mae: 0.2151\n",
            "Epoch 198/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2153 - val_loss: 0.1070 - val_mae: 0.2151\n",
            "Epoch 199/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1070 - val_mae: 0.2150\n",
            "Epoch 200/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1070 - val_mae: 0.2150\n",
            "Epoch 201/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1070 - val_mae: 0.2150\n",
            "Epoch 202/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2150\n",
            "Epoch 203/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2151\n",
            "Epoch 204/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2151\n",
            "Epoch 205/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1071 - val_mae: 0.2151\n",
            "Epoch 206/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 207/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 208/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2151\n",
            "Epoch 209/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1072 - val_mae: 0.2151\n",
            "Epoch 210/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2153 - val_loss: 0.1073 - val_mae: 0.2151\n",
            "Epoch 211/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2151\n",
            "Epoch 212/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1073 - val_mae: 0.2150\n",
            "Epoch 213/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2150\n",
            "Epoch 214/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2150\n",
            "Epoch 215/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1070 - val_mae: 0.2149\n",
            "Epoch 216/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1070 - mae: 0.2150 - val_loss: 0.1073 - val_mae: 0.2152\n",
            "Epoch 217/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 218/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1073 - val_mae: 0.2150\n",
            "Epoch 219/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2151\n",
            "Epoch 220/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1070 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2151\n",
            "Epoch 221/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 222/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 223/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1070 - val_mae: 0.2147\n",
            "Epoch 224/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2150\n",
            "Epoch 225/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 226/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 227/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 228/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 229/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2147 - val_loss: 0.1071 - val_mae: 0.2150\n",
            "Epoch 230/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 231/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 232/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2152\n",
            "Epoch 233/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2150\n",
            "Epoch 234/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2150\n",
            "Epoch 235/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2150\n",
            "Epoch 236/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 237/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 238/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 239/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1070 - val_mae: 0.2147\n",
            "Epoch 240/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2147 - val_loss: 0.1070 - val_mae: 0.2147\n",
            "Epoch 241/400\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2147\n",
            "Epoch 242/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 243/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 244/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2150\n",
            "Epoch 245/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 246/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1070 - mae: 0.2148 - val_loss: 0.1070 - val_mae: 0.2150\n",
            "Epoch 247/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 248/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 249/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2146\n",
            "Epoch 250/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 251/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1073 - val_mae: 0.2149\n",
            "Epoch 252/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2147\n",
            "Epoch 253/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 254/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 255/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 256/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 257/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 258/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1070 - val_mae: 0.2147\n",
            "Epoch 259/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1070 - val_mae: 0.2146\n",
            "Epoch 260/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2147 - val_loss: 0.1070 - val_mae: 0.2146\n",
            "Epoch 261/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1070 - val_mae: 0.2145\n",
            "Epoch 262/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1070 - val_mae: 0.2147\n",
            "Epoch 263/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1069 - val_mae: 0.2146\n",
            "Epoch 264/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 265/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 266/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 267/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1073 - val_mae: 0.2148\n",
            "Epoch 268/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2147 - val_loss: 0.1070 - val_mae: 0.2146\n",
            "Epoch 269/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1069 - val_mae: 0.2147\n",
            "Epoch 270/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 271/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 272/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1073 - val_mae: 0.2148\n",
            "Epoch 273/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 274/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2147 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 275/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1071 - val_mae: 0.2147\n",
            "Epoch 276/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 277/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1070 - val_mae: 0.2146\n",
            "Epoch 278/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2147\n",
            "Epoch 279/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 280/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1070 - val_mae: 0.2149\n",
            "Epoch 281/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 282/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 283/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 284/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2150\n",
            "Epoch 285/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1070 - val_mae: 0.2148\n",
            "Epoch 286/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 287/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 288/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2147 - val_loss: 0.1069 - val_mae: 0.2146\n",
            "Epoch 289/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 290/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1071 - val_mae: 0.2152\n",
            "Epoch 291/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 292/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 293/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2150\n",
            "Epoch 294/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1074 - val_mae: 0.2148\n",
            "Epoch 295/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1073 - val_mae: 0.2149\n",
            "Epoch 296/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1072 - val_mae: 0.2150\n",
            "Epoch 297/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2147\n",
            "Epoch 298/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1073 - val_mae: 0.2149\n",
            "Epoch 299/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1071 - val_mae: 0.2150\n",
            "Epoch 300/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 301/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 302/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1073 - val_mae: 0.2152\n",
            "Epoch 303/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 304/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2150\n",
            "Epoch 305/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 306/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 307/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 308/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 309/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1070 - val_mae: 0.2146\n",
            "Epoch 310/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 311/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 312/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1073 - val_mae: 0.2149\n",
            "Epoch 313/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2147\n",
            "Epoch 314/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 315/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1074 - val_mae: 0.2148\n",
            "Epoch 316/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1073 - val_mae: 0.2148\n",
            "Epoch 317/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2147 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 318/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 319/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 320/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2150\n",
            "Epoch 321/400\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1074 - val_mae: 0.2152\n",
            "Epoch 322/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1072 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 323/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1073 - val_mae: 0.2149\n",
            "Epoch 324/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 325/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2147 - val_loss: 0.1073 - val_mae: 0.2151\n",
            "Epoch 326/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1073 - val_mae: 0.2150\n",
            "Epoch 327/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1073 - val_mae: 0.2148\n",
            "Epoch 328/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2147\n",
            "Epoch 329/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2147\n",
            "Epoch 330/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2147\n",
            "Epoch 331/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 332/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 333/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 334/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1073 - val_mae: 0.2150\n",
            "Epoch 335/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 336/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1072 - val_mae: 0.2150\n",
            "Epoch 337/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 338/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 339/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 340/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 341/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1073 - val_mae: 0.2149\n",
            "Epoch 342/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1070 - val_mae: 0.2149\n",
            "Epoch 343/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 344/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1071 - val_mae: 0.2150\n",
            "Epoch 345/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1073 - val_mae: 0.2149\n",
            "Epoch 346/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1075 - val_mae: 0.2150\n",
            "Epoch 347/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1072 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 348/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 349/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1070 - mae: 0.2151 - val_loss: 0.1076 - val_mae: 0.2150\n",
            "Epoch 350/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2147 - val_loss: 0.1073 - val_mae: 0.2153\n",
            "Epoch 351/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 352/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1070 - val_mae: 0.2148\n",
            "Epoch 353/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 354/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 355/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1074 - val_mae: 0.2150\n",
            "Epoch 356/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1073 - val_mae: 0.2149\n",
            "Epoch 357/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 358/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 359/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 360/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 361/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 362/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2151\n",
            "Epoch 363/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2152 - val_loss: 0.1074 - val_mae: 0.2149\n",
            "Epoch 364/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1075 - val_mae: 0.2150\n",
            "Epoch 365/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 366/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 367/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1071 - val_mae: 0.2147\n",
            "Epoch 368/400\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 369/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1073 - val_mae: 0.2148\n",
            "Epoch 370/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1073 - val_mae: 0.2148\n",
            "Epoch 371/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1073 - val_mae: 0.2149\n",
            "Epoch 372/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1073 - val_mae: 0.2149\n",
            "Epoch 373/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 374/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 375/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2147 - val_loss: 0.1070 - val_mae: 0.2148\n",
            "Epoch 376/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 377/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 378/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2148\n",
            "Epoch 379/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 380/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1070 - mae: 0.2149 - val_loss: 0.1075 - val_mae: 0.2150\n",
            "Epoch 381/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2150\n",
            "Epoch 382/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1073 - val_mae: 0.2150\n",
            "Epoch 383/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2148 - val_loss: 0.1070 - val_mae: 0.2150\n",
            "Epoch 384/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1073 - val_mae: 0.2150\n",
            "Epoch 385/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 386/400\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2153\n",
            "Epoch 387/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2152 - val_loss: 0.1071 - val_mae: 0.2150\n",
            "Epoch 388/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 389/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2151 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 390/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1073 - val_mae: 0.2149\n",
            "Epoch 391/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1073 - val_mae: 0.2151\n",
            "Epoch 392/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1074 - val_mae: 0.2149\n",
            "Epoch 393/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1073 - val_mae: 0.2151\n",
            "Epoch 394/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 395/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1072 - mae: 0.2151 - val_loss: 0.1071 - val_mae: 0.2149\n",
            "Epoch 396/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 397/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1071 - mae: 0.2149 - val_loss: 0.1072 - val_mae: 0.2150\n",
            "Epoch 398/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2149\n",
            "Epoch 399/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1071 - mae: 0.2150 - val_loss: 0.1072 - val_mae: 0.2148\n",
            "Epoch 400/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2149 - val_loss: 0.1071 - val_mae: 0.2147\n"
          ]
        }
      ],
      "source": [
        "# build the model and train it\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu')) # relu is used for performance\n",
        "model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')) # softmax is used, because we only expect one class to occur per input\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "history = model.fit(inputs_train, outputs_train, epochs=400, batch_size=4, validation_data=(inputs_validate, outputs_validate))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guMjtfa42ahM"
      },
      "source": [
        "### Run with Test Data\n",
        "Put our test data into the model and plot the predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "V3Y0CCWJz2EK",
        "outputId": "f02a198e-c110-42c0-dc94-cc088065d528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step\n",
            "predictions =\n",
            " [[0.204 0.194 0.203 ... 0.211 0.    0.   ]\n",
            " [0.201 0.189 0.209 ... 0.211 0.    0.   ]\n",
            " [0.012 0.013 0.008 ... 0.011 0.493 0.456]\n",
            " ...\n",
            " [0.213 0.215 0.173 ... 0.207 0.023 0.01 ]\n",
            " [0.201 0.19  0.208 ... 0.21  0.    0.   ]\n",
            " [0.207 0.199 0.199 ... 0.212 0.    0.   ]]\n",
            "actual =\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "x has 3 columns but y has 7 columns",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-797f8421ff49>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training data predicted vs actual values'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Predicted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mncx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mncx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mncy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mncx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mncy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"x has {ncx} columns but y has {ncy} columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mncx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mncy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x has 3 columns but y has 7 columns"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0UAAACPCAYAAAA1HHD6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlp0lEQVR4nO3de1RNef8H8PepdE50Vyqmicq9yK9cyiVMM5lpmFyLGZfIZTDG9LgzklvzDIMZg9yGGR4UE2bcEy0zZDwog8GgXEcldCFKne/vD6v9OJ3T5aSLnPdrrbOW8z3f796fvfdnp8/Ze3+TCSEEiIiIiIiIdJRedQdARERERERUnVgUERERERGRTmNRREREREREOo1FERERERER6TQWRUREREREpNNYFBERERERkU5jUURERERERDqNRREREREREek0FkVERERERKTTWBQRUbUaNmwYGjZsWK6xc+bMgUwmq9iAXlHXrl3RtWvX6g7jtSOTyTBnzhzp/caNGyGTyXDjxo1qi6moojGSdho2bIhhw4ZV+Xp53IioIrAoIiKNZDJZmV5xcXHVHeobIScnB3PmzOH+LMWWLVuwbNmy6g6jRmBOERGVnUF1B0BEr6dNmzapvP/pp58QExOj1t68efNXWs/atWuhVCrLNXbWrFmYNm3aK63/dZGTk4OwsDAA0IkrTYMHD0ZgYCDkcrlW47Zs2YILFy5g4sSJlRPYG0TXcoqI6FWwKCIijT755BOV9ydPnkRMTIxae1E5OTmoXbt2mddTq1atcsUHAAYGBjAw4I+xyqTt8SwrfX196OvrV/hyiYiIyoO3zxFRuXXt2hUuLi44c+YMunTpgtq1a2PGjBkAgN27d8PPzw/169eHXC6Hk5MT5s2bh4KCApVlFH2m6MaNG5DJZFi8eDHWrFkDJycnyOVytG3bFv/9739Vxmp6pkgmk2H8+PHYtWsXXFxcIJfL0bJlSxw4cEAt/ri4OHh4eEChUMDJyQmrV6/W6jmlwviMjIzQrl07/Pbbb2p98vLyMHv2bLi7u8PMzAx16tRB586dcfToUZVttra2BgCEhYVJtyYWPifx559/YtiwYXB0dIRCoYCtrS2GDx+OBw8elBpjXFwcZDIZIiMjMWPGDNja2qJOnTro1asXbt++rdK3pOOZm5uL0NBQODs7Qy6Xw97eHlOmTEFubq7KMnJzc/HFF1/A2toaJiYm6NWrF+7cuaMWV3HPFO3fvx/e3t4wMTGBqakp2rZtiy1btkjx7d27Fzdv3pT20cu5U9ExFpWamgoDAwPp6svLrly5AplMhu+//x4A8Pz5c4SFhaFx48ZQKBSoW7cuOnXqhJiYmBLX8fDhQ0yaNAmurq4wNjaGqakp3n//fZw7d06t77NnzzBnzhw0adIECoUCdnZ26NOnD65fv15qThX37JumZ/wWL14MLy8v1K1bF0ZGRnB3d8eOHTtK3V9FPX/+HJaWlggKClL7LCsrCwqFApMmTQJQtvOmOMU9p1jcub1582a4u7vDyMgIlpaWCAwMVDs3rl69ir59+8LW1hYKhQJvvfUWAgMDkZmZWcatJ6LXHb9iJaJX8uDBA7z//vsIDAzEJ598AhsbGwAvfuk1NjZGSEgIjI2NceTIEcyePRtZWVlYtGhRqcvdsmULsrOzMXr0aMhkMnz99dfo06cPkpKSSr269PvvvyM6Ohpjx46FiYkJvvvuO/Tt2xe3bt1C3bp1AQAJCQno0aMH7OzsEBYWhoKCAsydO1f6RbI069evx+jRo+Hl5YWJEyciKSkJvXr1gqWlJezt7aV+WVlZWLduHQYOHIiRI0ciOzsb69evh6+vL06dOgU3NzdYW1tj1apV+PTTT9G7d2/06dMHANCqVSsAQExMDJKSkhAUFARbW1tcvHgRa9aswcWLF3Hy5MkyFXELFiyATCbD1KlTkZaWhmXLlsHHxweJiYkwMjKS+mk6nkqlEr169cLvv/+OUaNGoXnz5jh//jyWLl2Kv//+G7t27ZLGBwcHY/PmzRg0aBC8vLxw5MgR+Pn5lWmfbty4EcOHD0fLli0xffp0mJubIyEhAQcOHMCgQYMwc+ZMZGZm4s6dO1i6dCkAwNjYGACqJEYbGxt4e3sjKioKoaGhKp9FRkZCX18f/fv3B/DiF/Dw8HAEBwejXbt2yMrKwunTp3H27Fm8++67xa4jKSkJu3btQv/+/dGoUSOkpqZi9erV8Pb2xl9//YX69esDAAoKCvDhhx8iNjYWgYGB+Pzzz5GdnY2YmBhcuHABPj4+JeaUNr799lv06tULH3/8MfLy8rBt2zb0798fe/bsKfOxBV5cFe7duzeio6OxevVqGBoaSp/t2rULubm5CAwMBFC286YiLFiwAF9++SUGDBiA4OBg3L9/H8uXL0eXLl2QkJAAc3Nz5OXlwdfXF7m5ufjss89ga2uLu3fvYs+ePcjIyICZmVmFxEJE1UwQEZXBuHHjRNEfGd7e3gKAiIiIUOufk5Oj1jZ69GhRu3Zt8ezZM6lt6NChwsHBQXqfnJwsAIi6deuKhw8fSu27d+8WAMSvv/4qtYWGhqrFBEAYGhqKa9euSW3nzp0TAMTy5cultp49e4ratWuLu3fvSm1Xr14VBgYGasssKi8vT9SrV0+4ubmJ3NxcqX3NmjUCgPD29pba8vPzVfoIIcSjR4+EjY2NGD58uNR2//59AUCEhoaqrU/Tvty6dasAII4dO1ZirEePHhUARIMGDURWVpbUHhUVJQCIb7/9Vmor7nhu2rRJ6Onpid9++02lPSIiQgAQx48fF0IIkZiYKACIsWPHqvQbNGiQ2rZt2LBBABDJyclCCCEyMjKEiYmJaN++vXj69KnKeKVSKf3bz89PJV8qM0ZNVq9eLQCI8+fPq7S3aNFCdO/eXXrfunVr4efnV+KyNHn27JkoKChQaUtOThZyuVzMnTtXavvhhx8EALFkyRK1ZRTur5JyytvbWyVPCxU9H4VQz7+8vDzh4uKisr1CCOHg4CCGDh1awtYJcfDgQbXzWAghPvjgA+Ho6Ci9L+t5I4RQ20ZN2yCE+s+LGzduCH19fbFgwQKVfufPnxcGBgZSe0JCggAgtm/fXuK2EVHNxtvniOiVyOVyjbfDvHz1ITs7G+np6ejcuTNycnJw+fLlUpcbEBAACwsL6X3nzp0BvPgmvTQ+Pj5wcnKS3rdq1QqmpqbS2IKCAhw+fBj+/v7SN+8A4OzsjPfff7/U5Z8+fRppaWkYM2aMyrfdw4YNU/vWWF9fX+qjVCrx8OFD5Ofnw8PDA2fPni11XYDqvnz27BnS09PRoUMHACjzMoYMGQITExPpfb9+/WBnZ4d9+/ap9NN0PLdv347mzZujWbNmSE9Pl17du3cHAOmWpsJlTZgwQWV8WSZFiImJQXZ2NqZNmwaFQqHyWVmuhFVFjADQp08fGBgYIDIyUmq7cOEC/vrrLwQEBEht5ubmuHjxIq5evVqm5RaSy+XQ03vxX3NBQQEePHgAY2NjNG3aVOVY//zzz7CyssJnn32mtoyKnqb+5fx79OgRMjMz0blz5zLn3su6d+8OKysrlf336NEjxMTEqOy/ijhvShMdHQ2lUokBAwao5IytrS0aN24s5UzhOX3w4EHk5ORUyLqJ6PXDooiIXkmDBg1UCoNCFy9eRO/evWFmZgZTU1NYW1tLkzSU5T78t99+W+V9YYH06NEjrccWji8cm5aWhqdPn8LZ2Vmtn6a2om7evAkAaNy4sUp7rVq14OjoqNb/xx9/RKtWraRnS6ytrbF3794yP4/w8OFDfP7557CxsYGRkRGsra3RqFEjAGXbl5pilclkcHZ2VnumR9PxvHr1Ki5evAhra2uVV5MmTQC82J/Ai/2ip6enUpACQNOmTUuN7/r16wAAFxeXMm1PUVURIwBYWVnhnXfeQVRUlNQWGRkJAwMD6RY1AJg7dy4yMjLQpEkTuLq6YvLkyfjzzz9LXb5SqcTSpUvRuHFjyOVyWFlZwdraGn/++afKsb5+/TqaNm1aJRON7NmzBx06dIBCoYClpaV0u2d5nqcxMDBA3759sXv3bulZr+joaDx//lylKAJe/bwpzdWrVyGEQOPGjdXy5tKlS1LONGrUCCEhIVi3bh2srKzg6+uLFStW8HkiojcMnykiolfy8rfIhTIyMuDt7Q1TU1PMnTsXTk5OUCgUOHv2LKZOnVqmKbiLm5lMCFGpYyva5s2bMWzYMPj7+2Py5MmoV68e9PX1ER4eLhUCpRkwYABOnDiByZMnw83NDcbGxlAqlejRo0e5pzMvjqbjqVQq4erqiiVLlmgc8/IzVNWlKmMMDAxEUFAQEhMT4ebmhqioKLzzzjuwsrKS+nTp0gXXr1/H7t27cejQIaxbtw5Lly5FREQEgoODi132woUL8eWXX2L48OGYN28eLC0toaenh4kTJ1bosZbJZBrPh6ITofz222/o1asXunTpgpUrV8LOzg61atXChg0bpAkwtBUYGIjVq1dj//798Pf3R1RUFJo1a4bWrVtLfV7lvCnuSlnRbVMqlZDJZNi/f7/GnxmFz6sBwDfffINhw4ZJx3PChAkIDw/HyZMn8dZbb2mz+UT0mmJRREQVLi4uDg8ePEB0dDS6dOkitScnJ1djVP9Tr149KBQKXLt2Te0zTW1FOTg4AHjxTXPh7VnAi9m1kpOTVX6527FjBxwdHREdHa3yy1rRB/WL+0Xu0aNHiI2NRVhYGGbPni21a3tbVtH+Qghcu3atTA/eOzk54dy5c3jnnXdKvDXLwcEBSqVSuopR6MqVK2VaB/DiVrSSrtYVt/6qiLGQv78/Ro8eLd0C9vfff2P69Olq/QpnWgsKCsLjx4/RpUsXzJkzp8SiaMeOHejWrRvWr1+v0p6RkaFSdDk5OeGPP/7A8+fPi514pKT9YGFhofFW1MKroIV+/vlnKBQKHDx4UOVvSm3YsKHYZZemS5cusLOzQ2RkJDp16oQjR45g5syZKn3Ket5oYmFhgYyMDLX2otvm5OQEIQQaNWokXVEsiaurK1xdXTFr1iycOHECHTt2REREBObPn1/qWCJ6/fH2OSKqcIXfur78TXReXh5WrlxZXSGp0NfXh4+PD3bt2oV//vlHar927Rr2799f6ngPDw9YW1sjIiICeXl5UvvGjRvVfhnTtC/++OMPxMfHq/Qr/FtAZRkPAMuWLSs1zpf99NNPyM7Olt7v2LED9+7dK9MzVAMGDMDdu3exdu1atc+ePn2KJ0+eAIC0rO+++07rWN977z2YmJggPDwcz549U/ns5W2vU6eOxtuWqiLGQubm5vD19UVUVBS2bdsGQ0ND+Pv7q/QpOl26sbExnJ2d1aYHL0pfX1/tWG/fvh13795Vaevbty/S09OlKcBfVji+uJwCXhQEly9fxv3796W2c+fO4fjx42rxyGQylassN27cUJnNT1t6enro168ffv31V2zatAn5+flqt86V9bzRxMnJCZmZmSq3K967dw87d+5U6denTx/o6+sjLCxMbZ8LIaRjmJWVhfz8fJXPXV1doaenV+rxJKKag1eKiKjCeXl5wcLCAkOHDsWECRMgk8mwadOmarl9rThz5szBoUOH0LFjR3z66acoKCjA999/DxcXFyQmJpY4tlatWpg/fz5Gjx6N7t27IyAgAMnJydiwYYPaM0UffvghoqOj0bt3b/j5+SE5ORkRERFo0aIFHj9+LPUzMjJCixYtEBkZiSZNmsDS0hIuLi5wcXFBly5d8PXXX+P58+do0KABDh06pPVVN0tLS3Tq1AlBQUFITU3FsmXL4OzsjJEjR5Y6dvDgwYiKisKYMWNw9OhRdOzYEQUFBbh8+TKioqJw8OBBeHh4wM3NDQMHDsTKlSuRmZkJLy8vxMbGlunqm6mpKZYuXYrg4GC0bdsWgwYNgoWFBc6dO4ecnBz8+OOPAAB3d3dERkYiJCQEbdu2hbGxMXr27FklMb4sICAAn3zyCVauXAlfX1+Ym5urfN6iRQt07doV7u7usLS0xOnTp7Fjxw6MHz++xOV++OGHmDt3LoKCguDl5YXz58/jP//5j1peDRkyBD/99BNCQkJw6tQpdO7cGU+ePMHhw4cxduxYfPTRRyXm1PDhw7FkyRL4+vpixIgRSEtLQ0REBFq2bImsrCxpPX5+fliyZAl69OiBQYMGIS0tDStWrICzs3OZnpEqaf8tX74coaGhcHV1RfPmzdX2Q1nOG00CAwMxdepU9O7dGxMmTEBOTg5WrVqFJk2aqEzS4OTkhPnz52P69Om4ceMG/P39YWJiguTkZOzcuROjRo3CpEmTcOTIEYwfPx79+/dHkyZNkJ+fj02bNkFfXx99+/Yt9z4gotdM1U94R0Q1UXFTcrds2VJj/+PHj4sOHToIIyMjUb9+fTFlyhRpOt6jR49K/YqbknvRokVqy0SRqXeLm5J73LhxamM1TRccGxsr2rRpIwwNDYWTk5NYt26d+Ne//iUUCkUxe0HVypUrRaNGjYRcLhceHh7i2LFjalMdK5VKsXDhQuHg4CDkcrlo06aN2LNnj8Zpg0+cOCHc3d2FoaGhyrbeuXNH9O7dW5ibmwszMzPRv39/8c8//5RpCunCKbm3bt0qpk+fLurVqyeMjIyEn5+fuHnzpkrfko5nXl6e+Pe//y1atmwp5HK5sLCwEO7u7iIsLExkZmZK/Z4+fSomTJgg6tatK+rUqSN69uwpbt++XeqU3IV++eUX4eXlJYyMjISpqalo166d2Lp1q/T548ePxaBBg4S5ubkAoLIPKzrGkmRlZQkjIyMBQGzevFnt8/nz54t27doJc3NzYWRkJJo1ayYWLFgg8vLySlzus2fPxL/+9S9hZ2cnjIyMRMeOHUV8fLzGKbRzcnLEzJkzRaNGjUStWrWEra2t6Nevn7h+/brUp7icEkKIzZs3C0dHR2FoaCjc3NzEwYMHNebl+vXrRePGjYVcLhfNmjUTGzZs0HjulWVK7kJKpVLY29sLAGL+/PkaPy/reaPpuB06dEi4uLgIQ0ND0bRpU7F582aNMQshxM8//yw6deok6tSpI+rUqSOaNWsmxo0bJ65cuSKEECIpKUkMHz5cODk5CYVCISwtLUW3bt3E4cOHy7StRFQzyIR4jb66JSKqZv7+/uWaSvl1FRcXh27dumH79u3o169fdYdDRET0WuIzRUSks54+fary/urVq9i3bx+6du1aPQERERFRteAzRUSksxwdHTFs2DA4Ojri5s2bWLVqFQwNDTFlypTqDo2IiIiqEIsiItJZPXr0wNatW5GSkgK5XA5PT08sXLhQ7Q+dEhER0ZtN62eKjh07hkWLFuHMmTPSFJdFpyItKi4uDiEhIbh48SLs7e0xa9YsDBs27BXCJiIiIiIiqhhaP1P05MkTtG7dGitWrChT/+TkZPj5+aFbt25ITEzExIkTERwcjIMHD2odLBERERERUUV7pdnnZDJZqVeKpk6dir179+LChQtSW2BgIDIyMnDgwIHyrpqIiIiIiKhCVPozRfHx8fDx8VFp8/X1xcSJE4sdk5ubq/JXopVKJR4+fIi6detCJpNVVqhERERERPSaE0IgOzsb9evXh55exUymXelFUUpKCmxsbFTabGxskJWVhadPn8LIyEhtTHh4OMLCwio7NCIiIiIiqqFu376Nt956q0KW9VrOPjd9+nSEhIRI7zMzM/H222/j9u3bMDU1rcbIiIiIiIioOmVlZcHe3h4mJiYVtsxKL4psbW2Rmpqq0paamgpTU1ONV4kAQC6XQy6Xq7WbmpqyKCIiIiIiogp9rKZibsIrgaenJ2JjY1XaYmJi4OnpWdmrJiIiIiIiKpXWRdHjx4+RmJiIxMREAC+m3E5MTMStW7cAvLj1bciQIVL/MWPGICkpCVOmTMHly5excuVKREVF4YsvvqiYLSAiIiIiInoFWhdFp0+fRps2bdCmTRsAQEhICNq0aYPZs2cDAO7duycVSADQqFEj7N27FzExMWjdujW++eYbrFu3Dr6+vhW0CUREREREROX3Sn+nqKpkZWXBzMwMmZmZfKaIiIiIiEiHVUZtUOnPFBEREREREb3OWBQREREREZFOY1FEREREREQ6jUURERERERHpNBZFRERERESk01gUERERERGRTmNRREREREREOo1FERERERER6TQWRUREREREpNNYFBERERERkU5jUURERERERDqNRREREREREek0FkVERERERKTTWBQREREREZFOY1FEREREREQ6jUURERERERHpNBZFRERERESk01gUERERERGRTmNRREREREREOo1FERERERER6TQWRUREREREpNNYFBERERERkU5jUURERERERDqNRREREREREek0FkVERERERKTTWBQREREREZFOY1FEREREREQ6rVxF0YoVK9CwYUMoFAq0b98ep06dKrbvxo0bIZPJVF4KhaLcARMREREREVUkrYuiyMhIhISEIDQ0FGfPnkXr1q3h6+uLtLS0YseYmpri3r170uvmzZuvFDQREREREVFF0booWrJkCUaOHImgoCC0aNECERERqF27Nn744Ydix8hkMtja2kovGxubVwqaiIiIiIioomhVFOXl5eHMmTPw8fH53wL09ODj44P4+Phixz1+/BgODg6wt7fHRx99hIsXL5Y/YiIiIiIiogqkVVGUnp6OgoICtSs9NjY2SElJ0TimadOm+OGHH7B7925s3rwZSqUSXl5euHPnTrHryc3NRVZWlsqLiIiIiIioMlT67HOenp4YMmQI3Nzc4O3tjejoaFhbW2P16tXFjgkPD4eZmZn0sre3r+wwiYiIiIhIR2lVFFlZWUFfXx+pqakq7ampqbC1tS3TMmrVqoU2bdrg2rVrxfaZPn06MjMzpdft27e1CZOIiIiIiKjMtCqKDA0N4e7ujtjYWKlNqVQiNjYWnp6eZVpGQUEBzp8/Dzs7u2L7yOVymJqaqryIiIiIiIgqg4G2A0JCQjB06FB4eHigXbt2WLZsGZ48eYKgoCAAwJAhQ9CgQQOEh4cDAObOnYsOHTrA2dkZGRkZWLRoEW7evIng4OCK3RIiIiIiIqJy0LooCggIwP379zF79mykpKTAzc0NBw4ckCZfuHXrFvT0/ncB6tGjRxg5ciRSUlJgYWEBd3d3nDhxAi1atKi4rSAiIiIiIionmRBCVHcQpcnKyoKZmRkyMzN5Kx0RERERkQ6rjNqg0mefIyIiIiIiep2xKCIiIiIiIp3GooiIiIiIiHQaiyIiIiIiItJpLIqIiIiIiEinsSgiIiIiIiKdxqKIiIiIiIh0GosiIiIiIiLSaSyKiIiIiIhIp7EoIiIiIiIincaiiIiIiIiIdBqLIiIiIiIi0mksioiIiIiISKexKCIiIiIiIp3GooiIiIiIiHQaiyIiIiIiItJpLIqIiIiIiEinsSgiIiIiIiKdxqKIiIiIiIh0GosiIiIiIiLSaSyKiIiIiIhIp7EoIiIiIiIincaiiIiIiIiIdBqLIiIiIiIi0mksioiIiIiISKexKCIiIiIiIp3GooiIiIiIiHQaiyIiIiIiItJp5SqKVqxYgYYNG0KhUKB9+/Y4depUif23b9+OZs2aQaFQwNXVFfv27StXsERERERERBVN66IoMjISISEhCA0NxdmzZ9G6dWv4+voiLS1NY/8TJ05g4MCBGDFiBBISEuDv7w9/f39cuHDhlYMnIiIiIiJ6VTIhhNBmQPv27dG2bVt8//33AAClUgl7e3t89tlnmDZtmlr/gIAAPHnyBHv27JHaOnToADc3N0RERJRpnVlZWTAzM0NmZiZMTU21CZeIiIiIiN4glVEbGGjTOS8vD2fOnMH06dOlNj09Pfj4+CA+Pl7jmPj4eISEhKi0+fr6YteuXcWuJzc3F7m5udL7zMxMAC92ABERERER6a7CmkDLazsl0qooSk9PR0FBAWxsbFTabWxscPnyZY1jUlJSNPZPSUkpdj3h4eEICwtTa7e3t9cmXCIiIiIiekM9ePAAZmZmFbIsrYqiqjJ9+nSVq0sZGRlwcHDArVu3KmzDiTTJysqCvb09bt++zVs1qVIx16iqMNeoqjDXqKpkZmbi7bffhqWlZYUtU6uiyMrKCvr6+khNTVVpT01Nha2trcYxtra2WvUHALlcDrlcrtZuZmbGk4yqhKmpKXONqgRzjaoKc42qCnONqoqeXsX9dSGtlmRoaAh3d3fExsZKbUqlErGxsfD09NQ4xtPTU6U/AMTExBTbn4iIiIiIqCppfftcSEgIhg4dCg8PD7Rr1w7Lli3DkydPEBQUBAAYMmQIGjRogPDwcADA559/Dm9vb3zzzTfw8/PDtm3bcPr0aaxZs6Zit4SIiIiIiKgctC6KAgICcP/+fcyePRspKSlwc3PDgQMHpMkUbt26pXIpy8vLC1u2bMGsWbMwY8YMNG7cGLt27YKLi0uZ1ymXyxEaGqrxljqiisRco6rCXKOqwlyjqsJco6pSGbmm9d8pIiIiIiIiepNU3NNJRERERERENRCLIiIiIiIi0mksioiIiIiISKexKCIiIiIiIp322hRFK1asQMOGDaFQKNC+fXucOnWqxP7bt29Hs2bNoFAo4Orqin379lVRpFTTaZNra9euRefOnWFhYQELCwv4+PiUmptEhbT9uVZo27ZtkMlk8Pf3r9wA6Y2hba5lZGRg3LhxsLOzg1wuR5MmTfj/KJWJtrm2bNkyNG3aFEZGRrC3t8cXX3yBZ8+eVVG0VBMdO3YMPXv2RP369SGTybBr165Sx8TFxeH//u//IJfL4ezsjI0bN2q93teiKIqMjERISAhCQ0Nx9uxZtG7dGr6+vkhLS9PY/8SJExg4cCBGjBiBhIQE+Pv7w9/fHxcuXKjiyKmm0TbX4uLiMHDgQBw9ehTx8fGwt7fHe++9h7t371Zx5FTTaJtrhW7cuIFJkyahc+fOVRQp1XTa5lpeXh7effdd3LhxAzt27MCVK1ewdu1aNGjQoIojp5pG21zbsmULpk2bhtDQUFy6dAnr169HZGQkZsyYUcWRU03y5MkTtG7dGitWrChT/+TkZPj5+aFbt25ITEzExIkTERwcjIMHD2q3YvEaaNeunRg3bpz0vqCgQNSvX1+Eh4dr7D9gwADh5+en0ta+fXsxevToSo2Taj5tc62o/Px8YWJiIn788cfKCpHeEOXJtfz8fOHl5SXWrVsnhg4dKj766KMqiJRqOm1zbdWqVcLR0VHk5eVVVYj0htA218aNGye6d++u0hYSEiI6duxYqXHSmwOA2LlzZ4l9pkyZIlq2bKnSFhAQIHx9fbVaV7VfKcrLy8OZM2fg4+Mjtenp6cHHxwfx8fEax8THx6v0BwBfX99i+xMB5cu1onJycvD8+XNYWlpWVpj0Bihvrs2dOxf16tXDiBEjqiJMegOUJ9d++eUXeHp6Yty4cbCxsYGLiwsWLlyIgoKCqgqbaqDy5JqXlxfOnDkj3WKXlJSEffv24YMPPqiSmEk3VFRdYFCRQZVHeno6CgoKYGNjo9JuY2ODy5cvaxyTkpKisX9KSkqlxUk1X3lyraipU6eifv36aicf0cvKk2u///471q9fj8TExCqIkN4U5cm1pKQkHDlyBB9//DH27duHa9euYezYsXj+/DlCQ0OrImyqgcqTa4MGDUJ6ejo6deoEIQTy8/MxZswY3j5HFaq4uiArKwtPnz6FkZFRmZZT7VeKiGqKr776Ctu2bcPOnTuhUCiqOxx6g2RnZ2Pw4MFYu3YtrKysqjscesMplUrUq1cPa9asgbu7OwICAjBz5kxERERUd2j0homLi8PChQuxcuVKnD17FtHR0di7dy/mzZtX3aERqan2K0VWVlbQ19dHamqqSntqaipsbW01jrG1tdWqPxFQvlwrtHjxYnz11Vc4fPgwWrVqVZlh0htA21y7fv06bty4gZ49e0ptSqUSAGBgYIArV67AycmpcoOmGqk8P9fs7OxQq1Yt6OvrS23NmzdHSkoK8vLyYGhoWKkxU81Unlz78ssvMXjwYAQHBwMAXF1d8eTJE4waNQozZ86Enh6/m6dXV1xdYGpqWuarRMBrcKXI0NAQ7u7uiI2NldqUSiViY2Ph6empcYynp6dKfwCIiYkptj8RUL5cA4Cvv/4a8+bNw4EDB+Dh4VEVoVINp22uNWvWDOfPn0diYqL06tWrlzSTjr29fVWGTzVIeX6udezYEdeuXZMKbwD4+++/YWdnx4KIilWeXMvJyVErfAqL8RfP0BO9ugqrC7SbA6JybNu2TcjlcrFx40bx119/iVGjRglzc3ORkpIihBBi8ODBYtq0aVL/48ePCwMDA7F48WJx6dIlERoaKmrVqiXOnz9fXZtANYS2ufbVV18JQ0NDsWPHDnHv3j3plZ2dXV2bQDWEtrlWFGefo7LSNtdu3bolTExMxPjx48WVK1fEnj17RL169cT8+fOraxOohtA210JDQ4WJiYnYunWrSEpKEocOHRJOTk5iwIAB1bUJVANkZ2eLhIQEkZCQIACIJUuWiISEBHHz5k0hhBDTpk0TgwcPlvonJSWJ2rVri8mTJ4tLly6JFStWCH19fXHgwAGt1vtaFEVCCLF8+XLx9ttvC0NDQ9GuXTtx8uRJ6TNvb28xdOhQlf5RUVGiSZMmwtDQULRs2VLs3bu3iiOmmkqbXHNwcBAA1F6hoaFVHzjVONr+XHsZiyLShra5duLECdG+fXshl8uFo6OjWLBggcjPz6/iqKkm0ibXnj9/LubMmSOcnJyEQqEQ9vb2YuzYseLRo0dVHzjVGEePHtX4u1dhbg0dOlR4e3urjXFzcxOGhobC0dFRbNiwQev1yoTg9UsiIiIiItJd1f5MERERERERUXViUURERERERDqNRREREREREek0FkVERERERKTTWBQREREREZFOY1FEREREREQ6jUURERERERHpNBZFRERERESk01gUERERERGRTmNRREREREREOo1FERERERER6TQWRUREREREpNP+Hwv2zDxIZePfAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# use the model to predict the test inputs\n",
        "predictions = model.predict(inputs_test)\n",
        "\n",
        "# print the predictions and the expected ouputs\n",
        "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
        "print(\"actual =\\n\", outputs_test)\n",
        "\n",
        "# Plot the predictions along with to the test data\n",
        "plt.clf()\n",
        "plt.title('Training data predicted vs actual values')\n",
        "plt.plot(inputs_test, outputs_test, 'b.', label='Actual')\n",
        "plt.plot(inputs_test, predictions, 'r.', label='Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7DO6xxXVCym"
      },
      "source": [
        "# Convert the Trained Model to Tensor Flow Lite\n",
        "\n",
        "The next cell converts the model to TFlite format. The size in bytes of the model is also printed out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Xn1-Rn9Cp_8"
      },
      "outputs": [],
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Model is %d bytes\" % basic_model_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykccQn7SXrUX"
      },
      "source": [
        "## Encode the Model in an Arduino Header File\n",
        "\n",
        "The next cell creates a constant byte array that contains the TFlite model. Import it as a tab with the sketch below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9J33uwpNtAku"
      },
      "outputs": [],
      "source": [
        "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
        "!cat gesture_model.tflite | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eSkHZaLzMId"
      },
      "source": [
        "# Realtime Classification of Sensor Data on Arduino\n",
        "\n",
        "Now it's time to switch back to the tutorial instructions and run our new model on the [Arduino Nano 33 BLE Sense](https://www.arduino.cc/en/Guide/NANO33BLE)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "FruitToEmoji-GIT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
