{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FruitToEmoji-GIT.ipynb",
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f92-4Hjy7kA8"
      },
      "source": [
        "<a href=\"https://www.arduino.cc/\"><img src=\"https://raw.githubusercontent.com/sandeepmistry/aimldevfest-workshop-2019/master/images/Arduino_logo_R_highquality.png\" width=200/></a>\n",
        "# Tiny ML on Arduino\n",
        "## Classify objects by color tutorial\n",
        "\n",
        "\n",
        "https://github.com/arduino/ArduinoTensorFlowLiteTutorials/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvDA8AK7QOq-"
      },
      "source": [
        "## Setup Python Environment\n",
        "\n",
        "The next cell sets up the dependencies in required for the notebook, run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2gs-PL4xDkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cee9d29-d6a8-46c5-8272-4baa6aa2fd4b"
      },
      "source": [
        "# Setup environment\n",
        "!apt-get -qq install xxd\n",
        "!pip install pandas numpy matplotlib\n",
        "%tensorflow_version 2.x\n",
        "!pip install tensorflow"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lwkeshJk7dg"
      },
      "source": [
        "# Upload Data\n",
        "\n",
        "1. Open the panel on the left side of Colab by clicking on the __>__\n",
        "1. Select the Files tab\n",
        "1. Drag `csv` files from your computer to the tab to upload them into colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSxUeYPNQbOg"
      },
      "source": [
        "# Train Neural Network\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxk414PU3oy3"
      },
      "source": [
        "## Parse and prepare the data\n",
        "\n",
        "The next cell parses the csv files and transforms them to a format that will be used to train the full connected neural network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGChd1FAk5_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "cdca129a-82aa-41da-99e3-35f8d1a1aedc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import fileinput\n",
        "import random\n",
        "\n",
        "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
        "\n",
        "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
        "# the same random numbers each time the notebook is run\n",
        "SEED = random.randint(0, 65535)\n",
        "print(\"SEED is currently is {}\".format(SEED))\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "CLASSES = [];\n",
        "\n",
        "for file in os.listdir(\"/content/\"):\n",
        "    if file.endswith(\".csv\"):\n",
        "        CLASSES.append(os.path.splitext(file)[0])\n",
        "\n",
        "CLASSES.sort()\n",
        "\n",
        "SAMPLES_WINDOW_LEN = 1\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "# create a one-hot encoded matrix that is used in the output\n",
        "ONE_HOT_ENCODED_CLASSES = np.eye(NUM_CLASSES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# read each csv file and push an input and output\n",
        "for class_index in range(NUM_CLASSES):\n",
        "  objectClass = CLASSES[class_index]\n",
        "  df = pd.read_csv(\"/content/\" + objectClass + \".csv\")\n",
        "  columns = list(df)\n",
        "  # get rid of pesky empty value lines of csv which cause NaN inputs to TensorFlow\n",
        "  df = df.dropna()\n",
        "  df = df.reset_index(drop=True)\n",
        "\n",
        "  # calculate the number of objectClass recordings in the file\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_WINDOW_LEN)\n",
        "  print(f\"\\u001b[32;4m{objectClass}\\u001b[0m class will be output \\u001b[32m{class_index}\\u001b[0m of the classifier\")\n",
        "  print(f\"{num_recordings} samples captured for training with inputs {list(df)} \\n\")\n",
        "\n",
        "  # graphing\n",
        "  plt.rcParams[\"figure.figsize\"] = (10,1)\n",
        "  pixels = np.array([df['Red'],df['Green'],df['Blue']],float)\n",
        "  pixels = np.transpose(pixels)\n",
        "  for i in range(num_recordings):\n",
        "    plt.axvline(x=i, linewidth=8, color=tuple(pixels[i]/np.max(pixels[i], axis=0)))\n",
        "  plt.show()\n",
        "\n",
        "  #tensors\n",
        "  output = ONE_HOT_ENCODED_CLASSES[class_index]\n",
        "  for i in range(num_recordings):\n",
        "    tensor = []\n",
        "    row = []\n",
        "    for c in columns:\n",
        "      row.append(df[c][i])\n",
        "    tensor += row\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "# convert the list to numpy array\n",
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "print(\"Data set parsing and preparation complete.\")\n",
        "\n",
        "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
        "# https://stackoverflow.com/a/37710486/2020087\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "print(\"Data set randomization and splitting complete.\")\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version = 2.15.0\n",
            "\n",
            "SEED is currently is 6040\n",
            "\u001b[32;4mapple\u001b[0m class will be output \u001b[32m0\u001b[0m of the classifier\n",
            "71 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;4mbanana\u001b[0m class will be output \u001b[32m1\u001b[0m of the classifier\n",
            "94 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;4morange\u001b[0m class will be output \u001b[32m2\u001b[0m of the classifier\n",
            "91 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data set parsing and preparation complete.\n",
            "Data set randomization and splitting complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8qlSAX1b6Yv"
      },
      "source": [
        "## Build & Train the Model\n",
        "\n",
        "Build and train a [TensorFlow](https://www.tensorflow.org) model using the high-level [Keras](https://www.tensorflow.org/guide/keras) API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGNFa-lX24Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19540c3f-6574-4355-d48f-56d1828caf38"
      },
      "source": [
        "# build the model and train it\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.Input(shape=(3,)))\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu')) # relu is used for performance\n",
        "model.add(tf.keras.layers.Dense(20, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(24, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(28, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(27, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(18, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(12, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(9, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')) # softmax is used, because we only expect one class to occur per input\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "history = model.fit(inputs_train, outputs_train, epochs=400, batch_size=4, validation_data=(inputs_validate, outputs_validate))\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "39/39 [==============================] - 1s 7ms/step - loss: 0.2220 - mae: 0.4442 - val_loss: 0.2224 - val_mae: 0.4446\n",
            "Epoch 2/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2207 - mae: 0.4428 - val_loss: 0.2216 - val_mae: 0.4438\n",
            "Epoch 3/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2172 - mae: 0.4392 - val_loss: 0.2179 - val_mae: 0.4394\n",
            "Epoch 4/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2036 - mae: 0.4241 - val_loss: 0.2060 - val_mae: 0.4266\n",
            "Epoch 5/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1688 - mae: 0.3783 - val_loss: 0.1602 - val_mae: 0.3683\n",
            "Epoch 6/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1318 - mae: 0.3184 - val_loss: 0.1272 - val_mae: 0.3145\n",
            "Epoch 7/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1002 - mae: 0.2622 - val_loss: 0.0985 - val_mae: 0.2571\n",
            "Epoch 8/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0822 - mae: 0.2255 - val_loss: 0.1653 - val_mae: 0.2948\n",
            "Epoch 9/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0667 - mae: 0.1928 - val_loss: 0.0739 - val_mae: 0.2085\n",
            "Epoch 10/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0479 - mae: 0.1575 - val_loss: 0.0790 - val_mae: 0.2005\n",
            "Epoch 11/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0429 - mae: 0.1364 - val_loss: 0.0273 - val_mae: 0.1212\n",
            "Epoch 12/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1071 - val_loss: 0.0170 - val_mae: 0.0934\n",
            "Epoch 13/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1021 - val_loss: 0.0147 - val_mae: 0.0840\n",
            "Epoch 14/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0252 - mae: 0.0843 - val_loss: 0.0204 - val_mae: 0.0783\n",
            "Epoch 15/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0722 - val_loss: 0.0379 - val_mae: 0.1007\n",
            "Epoch 16/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.0784 - val_loss: 0.0047 - val_mae: 0.0425\n",
            "Epoch 17/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0255 - mae: 0.0754 - val_loss: 0.0447 - val_mae: 0.1059\n",
            "Epoch 18/400\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0153 - mae: 0.0589 - val_loss: 0.0117 - val_mae: 0.0517\n",
            "Epoch 19/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.0699 - val_loss: 0.0025 - val_mae: 0.0301\n",
            "Epoch 20/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0193 - mae: 0.0542 - val_loss: 0.1427 - val_mae: 0.2105\n",
            "Epoch 21/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0210 - mae: 0.0598 - val_loss: 0.1206 - val_mae: 0.1923\n",
            "Epoch 22/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0549 - val_loss: 0.0018 - val_mae: 0.0230\n",
            "Epoch 23/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.0625 - val_loss: 0.0046 - val_mae: 0.0281\n",
            "Epoch 24/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0417 - val_loss: 0.0019 - val_mae: 0.0214\n",
            "Epoch 25/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0227 - mae: 0.0520 - val_loss: 9.1645e-04 - val_mae: 0.0182\n",
            "Epoch 26/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.0540 - val_loss: 9.4648e-04 - val_mae: 0.0179\n",
            "Epoch 27/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0235 - mae: 0.0543 - val_loss: 0.0022 - val_mae: 0.0192\n",
            "Epoch 28/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0211 - mae: 0.0456 - val_loss: 8.5354e-04 - val_mae: 0.0159\n",
            "Epoch 29/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0203 - mae: 0.0439 - val_loss: 0.0019 - val_mae: 0.0174\n",
            "Epoch 30/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0388 - val_loss: 0.1204 - val_mae: 0.1834\n",
            "Epoch 31/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.0515 - val_loss: 0.1519 - val_mae: 0.2072\n",
            "Epoch 32/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.0511 - val_loss: 0.0023 - val_mae: 0.0175\n",
            "Epoch 33/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.0532 - val_loss: 7.8275e-04 - val_mae: 0.0161\n",
            "Epoch 34/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0323 - val_loss: 8.9710e-04 - val_mae: 0.0156\n",
            "Epoch 35/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0250 - mae: 0.0469 - val_loss: 0.0312 - val_mae: 0.0678\n",
            "Epoch 36/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0195 - mae: 0.0438 - val_loss: 6.8969e-04 - val_mae: 0.0118\n",
            "Epoch 37/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0212 - mae: 0.0392 - val_loss: 0.0022 - val_mae: 0.0201\n",
            "Epoch 38/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0304 - val_loss: 0.0022 - val_mae: 0.0201\n",
            "Epoch 39/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.0489 - val_loss: 0.0016 - val_mae: 0.0129\n",
            "Epoch 40/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0311 - val_loss: 7.5280e-04 - val_mae: 0.0103\n",
            "Epoch 41/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0224 - mae: 0.0423 - val_loss: 0.1050 - val_mae: 0.1551\n",
            "Epoch 42/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0394 - val_loss: 0.1630 - val_mae: 0.2137\n",
            "Epoch 43/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0234 - mae: 0.0419 - val_loss: 2.9827e-04 - val_mae: 0.0094\n",
            "Epoch 44/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0193 - mae: 0.0390 - val_loss: 0.0165 - val_mae: 0.0495\n",
            "Epoch 45/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0191 - mae: 0.0384 - val_loss: 4.9849e-04 - val_mae: 0.0091\n",
            "Epoch 46/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0225 - mae: 0.0430 - val_loss: 0.0065 - val_mae: 0.0208\n",
            "Epoch 47/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0208 - mae: 0.0352 - val_loss: 2.9938e-04 - val_mae: 0.0096\n",
            "Epoch 48/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0392 - val_loss: 3.4874e-04 - val_mae: 0.0097\n",
            "Epoch 49/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0347 - val_loss: 0.0784 - val_mae: 0.1175\n",
            "Epoch 50/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0230 - val_loss: 0.0982 - val_mae: 0.1351\n",
            "Epoch 51/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0396 - val_loss: 1.8187e-04 - val_mae: 0.0076\n",
            "Epoch 52/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0222 - mae: 0.0411 - val_loss: 0.0039 - val_mae: 0.0151\n",
            "Epoch 53/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0263 - val_loss: 0.0309 - val_mae: 0.0546\n",
            "Epoch 54/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0240 - val_loss: 8.7252e-04 - val_mae: 0.0094\n",
            "Epoch 55/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0366 - val_loss: 2.4614e-04 - val_mae: 0.0073\n",
            "Epoch 56/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.0465 - val_loss: 4.2751e-04 - val_mae: 0.0094\n",
            "Epoch 57/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0230 - val_loss: 2.1289e-04 - val_mae: 0.0065\n",
            "Epoch 58/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0283 - val_loss: 1.1340e-04 - val_mae: 0.0058\n",
            "Epoch 59/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0236 - mae: 0.0386 - val_loss: 1.8974e-04 - val_mae: 0.0069\n",
            "Epoch 60/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0235 - val_loss: 0.0494 - val_mae: 0.0751\n",
            "Epoch 61/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0244 - mae: 0.0428 - val_loss: 1.1159e-04 - val_mae: 0.0058\n",
            "Epoch 62/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0198 - val_loss: 6.6445e-04 - val_mae: 0.0128\n",
            "Epoch 63/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0203 - mae: 0.0345 - val_loss: 1.6896e-04 - val_mae: 0.0073\n",
            "Epoch 64/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0206 - mae: 0.0346 - val_loss: 0.0029 - val_mae: 0.0167\n",
            "Epoch 65/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0213 - val_loss: 7.7164e-05 - val_mae: 0.0047\n",
            "Epoch 66/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0237 - val_loss: 8.7575e-05 - val_mae: 0.0049\n",
            "Epoch 67/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0323 - val_loss: 3.2782e-04 - val_mae: 0.0059\n",
            "Epoch 68/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0298 - val_loss: 0.0018 - val_mae: 0.0102\n",
            "Epoch 69/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0209 - val_loss: 0.0022 - val_mae: 0.0096\n",
            "Epoch 70/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.0352 - val_loss: 0.0037 - val_mae: 0.0116\n",
            "Epoch 71/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0290 - val_loss: 3.4813e-04 - val_mae: 0.0092\n",
            "Epoch 72/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0135 - val_loss: 4.9530e-05 - val_mae: 0.0039\n",
            "Epoch 73/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0234 - val_loss: 0.1237 - val_mae: 0.1579\n",
            "Epoch 74/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0205 - mae: 0.0284 - val_loss: 5.1706e-05 - val_mae: 0.0042\n",
            "Epoch 75/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0356 - mae: 0.0499 - val_loss: 3.0651e-04 - val_mae: 0.0078\n",
            "Epoch 76/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.0392 - val_loss: 1.0361e-04 - val_mae: 0.0047\n",
            "Epoch 77/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0278 - val_loss: 0.0013 - val_mae: 0.0077\n",
            "Epoch 78/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0248 - val_loss: 1.1918e-04 - val_mae: 0.0057\n",
            "Epoch 79/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0138 - val_loss: 0.0020 - val_mae: 0.0092\n",
            "Epoch 80/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0242 - val_loss: 0.1620 - val_mae: 0.2020\n",
            "Epoch 81/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0296 - val_loss: 0.0024 - val_mae: 0.0096\n",
            "Epoch 82/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0269 - val_loss: 7.5106e-05 - val_mae: 0.0049\n",
            "Epoch 83/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0126 - val_loss: 1.6756e-04 - val_mae: 0.0043\n",
            "Epoch 84/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0276 - val_loss: 5.7791e-05 - val_mae: 0.0041\n",
            "Epoch 85/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.0339 - val_loss: 0.0014 - val_mae: 0.0148\n",
            "Epoch 86/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0151 - val_loss: 4.9320e-05 - val_mae: 0.0037\n",
            "Epoch 87/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0275 - val_loss: 5.5357e-05 - val_mae: 0.0040\n",
            "Epoch 88/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0272 - val_loss: 1.4641e-04 - val_mae: 0.0051\n",
            "Epoch 89/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0198 - mae: 0.0324 - val_loss: 0.0066 - val_mae: 0.0158\n",
            "Epoch 90/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.0348 - val_loss: 2.2905e-04 - val_mae: 0.0073\n",
            "Epoch 91/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0205 - val_loss: 0.0023 - val_mae: 0.0082\n",
            "Epoch 92/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0204 - val_loss: 2.7204e-05 - val_mae: 0.0031\n",
            "Epoch 93/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0195 - val_loss: 0.1270 - val_mae: 0.1524\n",
            "Epoch 94/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0200 - mae: 0.0325 - val_loss: 7.2913e-05 - val_mae: 0.0046\n",
            "Epoch 95/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0208 - val_loss: 0.0405 - val_mae: 0.0627\n",
            "Epoch 96/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0244 - val_loss: 2.7186e-05 - val_mae: 0.0030\n",
            "Epoch 97/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0207 - val_loss: 7.2037e-05 - val_mae: 0.0045\n",
            "Epoch 98/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0160 - val_loss: 2.4914e-05 - val_mae: 0.0023\n",
            "Epoch 99/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0188 - val_loss: 0.0011 - val_mae: 0.0062\n",
            "Epoch 100/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0159 - val_loss: 6.9688e-05 - val_mae: 0.0028\n",
            "Epoch 101/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0128 - val_loss: 1.9593e-05 - val_mae: 0.0025\n",
            "Epoch 102/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0207 - val_loss: 3.3233e-05 - val_mae: 0.0031\n",
            "Epoch 103/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0289 - val_loss: 3.7958e-05 - val_mae: 0.0022\n",
            "Epoch 104/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0178 - val_loss: 4.4260e-05 - val_mae: 0.0035\n",
            "Epoch 105/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0173 - val_loss: 0.0019 - val_mae: 0.0072\n",
            "Epoch 106/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0148 - val_loss: 2.9420e-04 - val_mae: 0.0049\n",
            "Epoch 107/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.0350 - val_loss: 2.4705e-04 - val_mae: 0.0068\n",
            "Epoch 108/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0200 - val_loss: 5.0617e-05 - val_mae: 0.0028\n",
            "Epoch 109/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0079 - val_loss: 4.1066e-05 - val_mae: 0.0027\n",
            "Epoch 110/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0203 - mae: 0.0262 - val_loss: 6.2592e-06 - val_mae: 0.0012\n",
            "Epoch 111/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0125 - val_loss: 3.2040e-05 - val_mae: 0.0028\n",
            "Epoch 112/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0075 - mae: 0.0130 - val_loss: 2.8495e-04 - val_mae: 0.0035\n",
            "Epoch 113/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0218 - val_loss: 2.0620e-05 - val_mae: 0.0018\n",
            "Epoch 114/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0153 - val_loss: 5.0659e-05 - val_mae: 0.0038\n",
            "Epoch 115/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0086 - val_loss: 4.5335e-05 - val_mae: 0.0026\n",
            "Epoch 116/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0104 - mae: 0.0186 - val_loss: 2.9986e-04 - val_mae: 0.0065\n",
            "Epoch 117/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0114 - val_loss: 1.3003e-04 - val_mae: 0.0032\n",
            "Epoch 118/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0075 - val_loss: 6.2953e-05 - val_mae: 0.0024\n",
            "Epoch 119/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0218 - mae: 0.0255 - val_loss: 1.0511e-05 - val_mae: 0.0018\n",
            "Epoch 120/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0134 - val_loss: 3.4107e-04 - val_mae: 0.0034\n",
            "Epoch 121/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0130 - val_loss: 1.5169e-05 - val_mae: 0.0018\n",
            "Epoch 122/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0191 - val_loss: 2.0190e-05 - val_mae: 0.0023\n",
            "Epoch 123/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0168 - val_loss: 8.5363e-05 - val_mae: 0.0047\n",
            "Epoch 124/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0116 - val_loss: 8.6310e-06 - val_mae: 0.0016\n",
            "Epoch 125/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0094 - val_loss: 2.5964e-05 - val_mae: 0.0024\n",
            "Epoch 126/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0130 - val_loss: 7.5006e-06 - val_mae: 0.0015\n",
            "Epoch 127/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0130 - val_loss: 0.1282 - val_mae: 0.1468\n",
            "Epoch 128/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.0395 - val_loss: 1.2853e-04 - val_mae: 0.0053\n",
            "Epoch 129/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0093 - val_loss: 1.3598e-05 - val_mae: 0.0020\n",
            "Epoch 130/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0223 - mae: 0.0298 - val_loss: 1.7737e-05 - val_mae: 0.0019\n",
            "Epoch 131/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0134 - val_loss: 1.9072e-05 - val_mae: 0.0022\n",
            "Epoch 132/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0069 - val_loss: 7.0950e-06 - val_mae: 0.0015\n",
            "Epoch 133/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.0247 - val_loss: 1.4693e-05 - val_mae: 0.0019\n",
            "Epoch 134/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0069 - val_loss: 1.0364e-05 - val_mae: 0.0017\n",
            "Epoch 135/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0065 - val_loss: 4.5618e-06 - val_mae: 0.0012\n",
            "Epoch 136/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0159 - val_loss: 8.2769e-06 - val_mae: 0.0011\n",
            "Epoch 137/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0139 - val_loss: 0.0053 - val_mae: 0.0090\n",
            "Epoch 138/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.0378 - val_loss: 5.5065e-06 - val_mae: 9.3607e-04\n",
            "Epoch 139/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0131 - val_loss: 0.1137 - val_mae: 0.1329\n",
            "Epoch 140/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0219 - val_loss: 0.0391 - val_mae: 0.0572\n",
            "Epoch 141/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0195 - mae: 0.0282 - val_loss: 8.7677e-05 - val_mae: 0.0026\n",
            "Epoch 142/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0206 - val_loss: 4.2951e-05 - val_mae: 0.0035\n",
            "Epoch 143/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0084 - val_loss: 1.6931e-05 - val_mae: 0.0023\n",
            "Epoch 144/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0067 - val_loss: 1.4528e-05 - val_mae: 0.0015\n",
            "Epoch 145/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0123 - val_loss: 5.5511e-06 - val_mae: 0.0012\n",
            "Epoch 146/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0060 - val_loss: 4.6302e-06 - val_mae: 0.0011\n",
            "Epoch 147/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0058 - val_loss: 2.4627e-06 - val_mae: 8.2976e-04\n",
            "Epoch 148/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0167 - val_loss: 2.4531e-05 - val_mae: 0.0011\n",
            "Epoch 149/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0072 - val_loss: 1.2319e-06 - val_mae: 5.7549e-04\n",
            "Epoch 150/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0063 - val_loss: 1.8767e-06 - val_mae: 7.4310e-04\n",
            "Epoch 151/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0075 - mae: 0.0114 - val_loss: 1.4613e-05 - val_mae: 0.0020\n",
            "Epoch 152/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0070 - val_loss: 3.9048e-06 - val_mae: 0.0011\n",
            "Epoch 153/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0057 - val_loss: 2.6430e-06 - val_mae: 8.4119e-04\n",
            "Epoch 154/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0086 - val_loss: 7.8820e-06 - val_mae: 0.0014\n",
            "Epoch 155/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0059 - val_loss: 2.6698e-06 - val_mae: 9.0412e-04\n",
            "Epoch 156/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0054 - val_loss: 1.2652e-06 - val_mae: 6.1053e-04\n",
            "Epoch 157/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0217 - mae: 0.0259 - val_loss: 7.1425e-05 - val_mae: 0.0032\n",
            "Epoch 158/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0151 - val_loss: 0.0021 - val_mae: 0.0059\n",
            "Epoch 159/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0100 - val_loss: 1.3216e-06 - val_mae: 6.4883e-04\n",
            "Epoch 160/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0053 - val_loss: 1.2999e-06 - val_mae: 6.5405e-04\n",
            "Epoch 161/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0052 - val_loss: 1.0873e-06 - val_mae: 5.9618e-04\n",
            "Epoch 162/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0127 - val_loss: 8.6974e-07 - val_mae: 4.9631e-04\n",
            "Epoch 163/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0052 - val_loss: 1.2705e-06 - val_mae: 5.8989e-04\n",
            "Epoch 164/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0051 - val_loss: 7.5775e-07 - val_mae: 4.9743e-04\n",
            "Epoch 165/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0066 - val_loss: 3.0927e-07 - val_mae: 2.8016e-04\n",
            "Epoch 166/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0105 - mae: 0.0124 - val_loss: 1.2407e-05 - val_mae: 0.0012\n",
            "Epoch 167/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0184 - val_loss: 1.3280e-06 - val_mae: 5.6211e-04\n",
            "Epoch 168/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0133 - val_loss: 3.3360e-06 - val_mae: 9.7580e-04\n",
            "Epoch 169/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0057 - val_loss: 2.7031e-06 - val_mae: 9.2139e-04\n",
            "Epoch 170/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0055 - val_loss: 1.8488e-06 - val_mae: 7.4661e-04\n",
            "Epoch 171/400\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.0053 - mae: 0.0075 - val_loss: 2.0062e-06 - val_mae: 4.9663e-04\n",
            "Epoch 172/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0214 - val_loss: 5.5580e-06 - val_mae: 0.0012\n",
            "Epoch 173/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0060 - val_loss: 2.6481e-06 - val_mae: 8.8838e-04\n",
            "Epoch 174/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0054 - val_loss: 1.1400e-06 - val_mae: 6.0391e-04\n",
            "Epoch 175/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0051 - val_loss: 5.5171e-07 - val_mae: 4.1900e-04\n",
            "Epoch 176/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0049 - val_loss: 4.2540e-07 - val_mae: 3.3739e-04\n",
            "Epoch 177/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0201 - val_loss: 3.0763e-06 - val_mae: 7.2869e-04\n",
            "Epoch 178/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0055 - val_loss: 1.4505e-06 - val_mae: 5.9455e-04\n",
            "Epoch 179/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0052 - val_loss: 9.1354e-07 - val_mae: 4.5541e-04\n",
            "Epoch 180/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0076 - val_loss: 1.4381e-04 - val_mae: 0.0026\n",
            "Epoch 181/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0132 - val_loss: 9.0568e-06 - val_mae: 5.3700e-04\n",
            "Epoch 182/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 1.4999e-07 - val_mae: 2.1630e-04\n",
            "Epoch 183/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0049 - val_loss: 1.7033e-07 - val_mae: 2.1577e-04\n",
            "Epoch 184/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0095 - val_loss: 2.2997e-07 - val_mae: 2.3989e-04\n",
            "Epoch 185/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0047 - val_loss: 1.5807e-07 - val_mae: 2.2107e-04\n",
            "Epoch 186/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0138 - val_loss: 1.5216e-07 - val_mae: 2.2485e-04\n",
            "Epoch 187/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 2.2291e-07 - val_mae: 2.6995e-04\n",
            "Epoch 188/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 1.9893e-07 - val_mae: 2.5596e-04\n",
            "Epoch 189/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0145 - val_loss: 6.8962e-07 - val_mae: 4.4382e-04\n",
            "Epoch 190/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0049 - val_loss: 3.5107e-07 - val_mae: 3.3901e-04\n",
            "Epoch 191/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 2.9546e-07 - val_mae: 3.1155e-04\n",
            "Epoch 192/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 2.5999e-07 - val_mae: 2.7918e-04\n",
            "Epoch 193/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0126 - val_loss: 1.5355e-06 - val_mae: 4.9921e-04\n",
            "Epoch 194/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0152 - val_loss: 2.5959e-04 - val_mae: 0.0020\n",
            "Epoch 195/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0082 - val_loss: 0.0040 - val_mae: 0.0077\n",
            "Epoch 196/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0105 - val_loss: 4.6006e-07 - val_mae: 3.7742e-04\n",
            "Epoch 197/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0049 - val_loss: 3.9921e-07 - val_mae: 3.5740e-04\n",
            "Epoch 198/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 3.0360e-07 - val_mae: 3.1908e-04\n",
            "Epoch 199/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 1.9030e-07 - val_mae: 2.4646e-04\n",
            "Epoch 200/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.0332 - val_loss: 0.0064 - val_mae: 0.0094\n",
            "Epoch 201/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0117 - val_loss: 5.7476e-07 - val_mae: 4.2251e-04\n",
            "Epoch 202/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0050 - val_loss: 5.4448e-07 - val_mae: 4.1323e-04\n",
            "Epoch 203/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0049 - val_loss: 4.5905e-07 - val_mae: 3.8550e-04\n",
            "Epoch 204/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0049 - val_loss: 5.0135e-05 - val_mae: 0.0011\n",
            "Epoch 205/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0077 - val_loss: 6.4959e-06 - val_mae: 0.0010\n",
            "Epoch 206/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0054 - val_loss: 1.5094e-06 - val_mae: 5.4708e-04\n",
            "Epoch 207/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0050 - val_loss: 4.3390e-07 - val_mae: 3.3204e-04\n",
            "Epoch 208/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 2.3266e-07 - val_mae: 2.5855e-04\n",
            "Epoch 209/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0207 - val_loss: 0.0012 - val_mae: 0.0041\n",
            "Epoch 210/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0150 - val_loss: 9.0032e-08 - val_mae: 1.7009e-04\n",
            "Epoch 211/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0149 - val_loss: 5.7250e-04 - val_mae: 0.0029\n",
            "Epoch 212/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0140 - val_loss: 6.6131e-07 - val_mae: 2.6489e-04\n",
            "Epoch 213/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0198 - val_loss: 2.9694e-07 - val_mae: 2.5632e-04\n",
            "Epoch 214/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0147 - val_loss: 2.3976e-06 - val_mae: 5.9269e-04\n",
            "Epoch 215/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.0287 - val_loss: 7.9229e-06 - val_mae: 0.0011\n",
            "Epoch 216/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0057 - val_loss: 2.4124e-06 - val_mae: 6.8298e-04\n",
            "Epoch 217/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0051 - val_loss: 8.2372e-07 - val_mae: 4.4436e-04\n",
            "Epoch 218/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0049 - val_loss: 4.3243e-07 - val_mae: 3.3377e-04\n",
            "Epoch 219/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0073 - val_loss: 0.0072 - val_mae: 0.0101\n",
            "Epoch 220/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0174 - val_loss: 0.0120 - val_mae: 0.0135\n",
            "Epoch 221/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0094 - val_loss: 2.1062e-07 - val_mae: 2.5167e-04\n",
            "Epoch 222/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 1.6461e-07 - val_mae: 2.3051e-04\n",
            "Epoch 223/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0047 - val_loss: 1.4796e-07 - val_mae: 2.1960e-04\n",
            "Epoch 224/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0047 - val_loss: 1.2088e-07 - val_mae: 1.9731e-04\n",
            "Epoch 225/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0076 - val_loss: 0.0023 - val_mae: 0.0100\n",
            "Epoch 226/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0174 - val_loss: 0.0037 - val_mae: 0.0071\n",
            "Epoch 227/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0151 - val_loss: 0.0267 - val_mae: 0.0338\n",
            "Epoch 228/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0121 - val_loss: 5.7457e-07 - val_mae: 4.2887e-04\n",
            "Epoch 229/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0049 - val_loss: 4.7363e-07 - val_mae: 3.9358e-04\n",
            "Epoch 230/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0049 - val_loss: 3.5207e-07 - val_mae: 3.4079e-04\n",
            "Epoch 231/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 2.4160e-07 - val_mae: 2.8233e-04\n",
            "Epoch 232/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0066 - val_loss: 5.9086e-06 - val_mae: 5.9223e-04\n",
            "Epoch 233/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0190 - mae: 0.0254 - val_loss: 1.0622e-06 - val_mae: 4.1582e-04\n",
            "Epoch 234/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0051 - val_loss: 6.0373e-07 - val_mae: 3.7972e-04\n",
            "Epoch 235/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0051 - val_loss: 5.4654e-06 - val_mae: 6.3484e-04\n",
            "Epoch 236/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0121 - val_loss: 5.9074e-07 - val_mae: 4.2161e-04\n",
            "Epoch 237/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0049 - val_loss: 4.4394e-07 - val_mae: 3.7150e-04\n",
            "Epoch 238/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 3.1440e-07 - val_mae: 3.1506e-04\n",
            "Epoch 239/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 2.1914e-07 - val_mae: 2.6361e-04\n",
            "Epoch 240/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0047 - val_loss: 1.5988e-07 - val_mae: 2.2428e-04\n",
            "Epoch 241/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0047 - val_loss: 1.1673e-07 - val_mae: 1.8696e-04\n",
            "Epoch 242/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0051 - val_loss: 0.0085 - val_mae: 0.0186\n",
            "Epoch 243/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0122 - val_loss: 1.0346e-06 - val_mae: 4.9642e-04\n",
            "Epoch 244/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0050 - val_loss: 4.7985e-07 - val_mae: 3.7101e-04\n",
            "Epoch 245/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 3.4848e-07 - val_mae: 3.1123e-04\n",
            "Epoch 246/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0047 - val_loss: 2.2804e-07 - val_mae: 2.5399e-04\n",
            "Epoch 247/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0143 - val_loss: 8.5448e-08 - val_mae: 1.5853e-04\n",
            "Epoch 248/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 7.8759e-08 - val_mae: 1.5437e-04\n",
            "Epoch 249/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 7.2265e-08 - val_mae: 1.4949e-04\n",
            "Epoch 250/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 6.7024e-08 - val_mae: 1.4451e-04\n",
            "Epoch 251/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0092 - val_loss: 2.3010e-05 - val_mae: 5.9425e-04\n",
            "Epoch 252/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0136 - val_loss: 0.0054 - val_mae: 0.0084\n",
            "Epoch 253/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0181 - mae: 0.0218 - val_loss: 9.9090e-08 - val_mae: 1.6968e-04\n",
            "Epoch 254/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 9.8294e-08 - val_mae: 1.6927e-04\n",
            "Epoch 255/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 8.8372e-08 - val_mae: 1.6520e-04\n",
            "Epoch 256/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 7.5863e-08 - val_mae: 1.5600e-04\n",
            "Epoch 257/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 6.6615e-08 - val_mae: 1.4551e-04\n",
            "Epoch 258/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 5.9251e-08 - val_mae: 1.3370e-04\n",
            "Epoch 259/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0211 - mae: 0.0275 - val_loss: 1.0146e-06 - val_mae: 3.3053e-04\n",
            "Epoch 260/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0091 - val_loss: 9.0009e-08 - val_mae: 1.3375e-04\n",
            "Epoch 261/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 7.5983e-08 - val_mae: 1.3006e-04\n",
            "Epoch 262/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 4.7273e-08 - val_mae: 1.1871e-04\n",
            "Epoch 263/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0160 - val_loss: 3.3082e-04 - val_mae: 0.0022\n",
            "Epoch 264/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0159 - val_loss: 7.7318e-07 - val_mae: 3.7920e-04\n",
            "Epoch 265/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0050 - val_loss: 2.5599e-07 - val_mae: 2.5830e-04\n",
            "Epoch 266/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0047 - val_loss: 2.2045e-07 - val_mae: 2.4354e-04\n",
            "Epoch 267/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0047 - val_loss: 1.6392e-07 - val_mae: 2.1763e-04\n",
            "Epoch 268/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0047 - val_loss: 1.2647e-07 - val_mae: 1.9527e-04\n",
            "Epoch 269/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 1.0515e-07 - val_mae: 1.7976e-04\n",
            "Epoch 270/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 8.7935e-08 - val_mae: 1.6315e-04\n",
            "Epoch 271/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0108 - val_loss: 5.1144e-08 - val_mae: 1.3021e-04\n",
            "Epoch 272/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 5.6118e-08 - val_mae: 1.3618e-04\n",
            "Epoch 273/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 5.5416e-08 - val_mae: 1.3535e-04\n",
            "Epoch 274/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 5.8336e-08 - val_mae: 1.3869e-04\n",
            "Epoch 275/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 8.3583e-08 - val_mae: 1.5104e-04\n",
            "Epoch 276/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0051 - val_loss: 9.9574e-08 - val_mae: 1.0349e-04\n",
            "Epoch 277/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0172 - val_loss: 5.2880e-08 - val_mae: 1.3212e-04\n",
            "Epoch 278/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0221 - mae: 0.0242 - val_loss: 0.0054 - val_mae: 0.0158\n",
            "Epoch 279/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0110 - val_loss: 3.0306e-07 - val_mae: 2.4770e-04\n",
            "Epoch 280/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0047 - val_loss: 1.5329e-07 - val_mae: 2.1789e-04\n",
            "Epoch 281/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 1.1998e-07 - val_mae: 1.9674e-04\n",
            "Epoch 282/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 9.3562e-08 - val_mae: 1.7476e-04\n",
            "Epoch 283/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 7.7224e-08 - val_mae: 1.5903e-04\n",
            "Epoch 284/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 6.6881e-08 - val_mae: 1.4802e-04\n",
            "Epoch 285/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 6.0632e-08 - val_mae: 1.4081e-04\n",
            "Epoch 286/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0046 - val_loss: 5.5661e-08 - val_mae: 1.3482e-04\n",
            "Epoch 287/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 5.0275e-08 - val_mae: 1.2799e-04\n",
            "Epoch 288/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 5.1264e-08 - val_mae: 1.2936e-04\n",
            "Epoch 289/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 4.3194e-08 - val_mae: 1.1840e-04\n",
            "Epoch 290/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 4.0072e-08 - val_mae: 1.1369e-04\n",
            "Epoch 291/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 3.8253e-08 - val_mae: 1.1125e-04\n",
            "Epoch 292/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 3.8933e-08 - val_mae: 1.1235e-04\n",
            "Epoch 293/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 3.4455e-08 - val_mae: 1.0551e-04\n",
            "Epoch 294/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 3.3809e-08 - val_mae: 1.0458e-04\n",
            "Epoch 295/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 3.0939e-08 - val_mae: 9.9720e-05\n",
            "Epoch 296/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 3.0927e-08 - val_mae: 9.9896e-05\n",
            "Epoch 297/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 2.9897e-08 - val_mae: 9.8100e-05\n",
            "Epoch 298/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 2.6767e-08 - val_mae: 9.2643e-05\n",
            "Epoch 299/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 2.8120e-08 - val_mae: 9.4832e-05\n",
            "Epoch 300/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 2.4920e-08 - val_mae: 8.9298e-05\n",
            "Epoch 301/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 2.4065e-08 - val_mae: 8.7679e-05\n",
            "Epoch 302/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 2.3474e-08 - val_mae: 8.6644e-05\n",
            "Epoch 303/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 2.3888e-08 - val_mae: 8.7244e-05\n",
            "Epoch 304/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 2.1208e-08 - val_mae: 8.2155e-05\n",
            "Epoch 305/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 2.0861e-08 - val_mae: 8.1506e-05\n",
            "Epoch 306/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.9270e-08 - val_mae: 7.7874e-05\n",
            "Epoch 307/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 2.0458e-08 - val_mae: 8.0625e-05\n",
            "Epoch 308/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.8960e-08 - val_mae: 7.7564e-05\n",
            "Epoch 309/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.9370e-08 - val_mae: 7.8318e-05\n",
            "Epoch 310/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.8201e-08 - val_mae: 7.5946e-05\n",
            "Epoch 311/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.8337e-08 - val_mae: 7.6103e-05\n",
            "Epoch 312/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.7791e-08 - val_mae: 7.4927e-05\n",
            "Epoch 313/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.6569e-08 - val_mae: 7.2309e-05\n",
            "Epoch 314/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.6521e-08 - val_mae: 7.2183e-05\n",
            "Epoch 315/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.5556e-08 - val_mae: 6.9935e-05\n",
            "Epoch 316/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.6212e-08 - val_mae: 7.1359e-05\n",
            "Epoch 317/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.5126e-08 - val_mae: 6.8981e-05\n",
            "Epoch 318/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.4900e-08 - val_mae: 6.8428e-05\n",
            "Epoch 319/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.4565e-08 - val_mae: 6.7635e-05\n",
            "Epoch 320/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.5200e-08 - val_mae: 6.8730e-05\n",
            "Epoch 321/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.3644e-08 - val_mae: 6.5366e-05\n",
            "Epoch 322/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.3506e-08 - val_mae: 6.5045e-05\n",
            "Epoch 323/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.3192e-08 - val_mae: 6.4243e-05\n",
            "Epoch 324/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.3045e-08 - val_mae: 6.3853e-05\n",
            "Epoch 325/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0045 - val_loss: 1.3497e-08 - val_mae: 6.4723e-05\n",
            "Epoch 326/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.3262e-08 - val_mae: 6.4114e-05\n",
            "Epoch 327/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.2059e-08 - val_mae: 6.1323e-05\n",
            "Epoch 328/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.1955e-08 - val_mae: 6.1045e-05\n",
            "Epoch 329/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.1778e-08 - val_mae: 6.0581e-05\n",
            "Epoch 330/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.1551e-08 - val_mae: 5.9965e-05\n",
            "Epoch 331/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.1485e-08 - val_mae: 5.9757e-05\n",
            "Epoch 332/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.1193e-08 - val_mae: 5.8985e-05\n",
            "Epoch 333/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.1021e-08 - val_mae: 5.8499e-05\n",
            "Epoch 334/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.1536e-08 - val_mae: 5.9555e-05\n",
            "Epoch 335/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.1720e-08 - val_mae: 5.9720e-05\n",
            "Epoch 336/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.0707e-08 - val_mae: 5.7556e-05\n",
            "Epoch 337/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.0403e-08 - val_mae: 5.6752e-05\n",
            "Epoch 338/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.0559e-08 - val_mae: 5.7028e-05\n",
            "Epoch 339/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.0337e-08 - val_mae: 5.6433e-05\n",
            "Epoch 340/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.0034e-08 - val_mae: 5.5638e-05\n",
            "Epoch 341/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.0625e-08 - val_mae: 5.6726e-05\n",
            "Epoch 342/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 1.0546e-08 - val_mae: 5.6424e-05\n",
            "Epoch 343/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 9.7128e-09 - val_mae: 5.4620e-05\n",
            "Epoch 344/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 9.1912e-09 - val_mae: 5.3242e-05\n",
            "Epoch 345/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 9.2956e-09 - val_mae: 5.3463e-05\n",
            "Epoch 346/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 9.0361e-09 - val_mae: 5.2736e-05\n",
            "Epoch 347/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 8.7868e-09 - val_mae: 5.2009e-05\n",
            "Epoch 348/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 8.5605e-09 - val_mae: 5.1321e-05\n",
            "Epoch 349/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 8.5584e-09 - val_mae: 5.1307e-05\n",
            "Epoch 350/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 8.7780e-09 - val_mae: 5.1824e-05\n",
            "Epoch 351/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 8.4696e-09 - val_mae: 5.0973e-05\n",
            "Epoch 352/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 8.2559e-09 - val_mae: 5.0338e-05\n",
            "Epoch 353/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 9.5926e-09 - val_mae: 5.2974e-05\n",
            "Epoch 354/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 8.3418e-09 - val_mae: 5.0452e-05\n",
            "Epoch 355/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 8.0482e-09 - val_mae: 4.9627e-05\n",
            "Epoch 356/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 8.1188e-09 - val_mae: 4.9752e-05\n",
            "Epoch 357/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 7.8352e-09 - val_mae: 4.8945e-05\n",
            "Epoch 358/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 7.7696e-09 - val_mae: 4.8717e-05\n",
            "Epoch 359/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 7.8609e-09 - val_mae: 4.8888e-05\n",
            "Epoch 360/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 7.6062e-09 - val_mae: 4.8166e-05\n",
            "Epoch 361/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 7.5123e-09 - val_mae: 4.7859e-05\n",
            "Epoch 362/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 7.0734e-09 - val_mae: 4.6457e-05\n",
            "Epoch 363/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 7.2336e-09 - val_mae: 4.6979e-05\n",
            "Epoch 364/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 7.4208e-09 - val_mae: 4.7434e-05\n",
            "Epoch 365/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 7.1341e-09 - val_mae: 4.6610e-05\n",
            "Epoch 366/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 7.0547e-09 - val_mae: 4.6338e-05\n",
            "Epoch 367/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.9847e-09 - val_mae: 4.6092e-05\n",
            "Epoch 368/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 7.5132e-09 - val_mae: 4.7276e-05\n",
            "Epoch 369/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 7.0532e-09 - val_mae: 4.6160e-05\n",
            "Epoch 370/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.6040e-09 - val_mae: 4.4831e-05\n",
            "Epoch 371/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.6370e-09 - val_mae: 4.4911e-05\n",
            "Epoch 372/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.6293e-09 - val_mae: 4.4848e-05\n",
            "Epoch 373/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.4427e-09 - val_mae: 4.4243e-05\n",
            "Epoch 374/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.6433e-09 - val_mae: 4.4783e-05\n",
            "Epoch 375/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.5824e-09 - val_mae: 4.4564e-05\n",
            "Epoch 376/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.4378e-09 - val_mae: 4.4114e-05\n",
            "Epoch 377/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.6513e-09 - val_mae: 4.4593e-05\n",
            "Epoch 378/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.8642e-09 - val_mae: 4.4966e-05\n",
            "Epoch 379/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.8209e-09 - val_mae: 4.4776e-05\n",
            "Epoch 380/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.2961e-09 - val_mae: 4.3488e-05\n",
            "Epoch 381/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.1467e-09 - val_mae: 4.3034e-05\n",
            "Epoch 382/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.0654e-09 - val_mae: 4.2757e-05\n",
            "Epoch 383/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.4951e-09 - val_mae: 4.0591e-05\n",
            "Epoch 384/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.0227e-09 - val_mae: 4.2540e-05\n",
            "Epoch 385/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.7573e-09 - val_mae: 4.1699e-05\n",
            "Epoch 386/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 6.3000e-09 - val_mae: 4.3054e-05\n",
            "Epoch 387/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.8297e-09 - val_mae: 4.1834e-05\n",
            "Epoch 388/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.6625e-09 - val_mae: 4.1303e-05\n",
            "Epoch 389/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.6782e-09 - val_mae: 4.1308e-05\n",
            "Epoch 390/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.8117e-09 - val_mae: 4.1609e-05\n",
            "Epoch 391/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.3771e-09 - val_mae: 4.0284e-05\n",
            "Epoch 392/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.6148e-09 - val_mae: 4.0980e-05\n",
            "Epoch 393/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.3338e-09 - val_mae: 4.0088e-05\n",
            "Epoch 394/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.4407e-09 - val_mae: 4.0392e-05\n",
            "Epoch 395/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.8821e-09 - val_mae: 4.1439e-05\n",
            "Epoch 396/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.2619e-09 - val_mae: 3.9766e-05\n",
            "Epoch 397/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.3601e-09 - val_mae: 4.0022e-05\n",
            "Epoch 398/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.2071e-09 - val_mae: 3.9524e-05\n",
            "Epoch 399/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.4260e-09 - val_mae: 4.0090e-05\n",
            "Epoch 400/400\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0044 - val_loss: 5.1953e-09 - val_mae: 3.9410e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guMjtfa42ahM"
      },
      "source": [
        "### Run with Test Data\n",
        "Put our test data into the model and plot the predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert inputs_test from (266,3) to (266,7)\n",
        "padding = NUM_CLASSES-3\n",
        "if padding > 0:\n",
        "  inputs_test_plt = np.hstack((inputs_test, np.zeros((266*padding)).reshape(266,padding)))\n",
        "else:\n",
        "  inputs_test_plt = inputs_test"
      ],
      "metadata": {
        "id": "VP7Ac9pFTRRh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Y0CCWJz2EK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62d021b4-94bd-4324-acc3-a3cd42ddaa79"
      },
      "source": [
        "# use the model to predict the test inputs\n",
        "predictions = model.predict(inputs_test)\n",
        "\n",
        "# print the predictions and the expected ouputs\n",
        "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
        "print(\"actual =\\n\", outputs_test)\n",
        "\n",
        "# Plot the predictions along with to the test data\n",
        "plt.clf()\n",
        "plt.title('Training data predicted vs actual values')\n",
        "plt.plot(inputs_test_plt, outputs_test, 'b.', label='Actual')\n",
        "plt.plot(inputs_test_plt, predictions, 'r.', label='Predicted')\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step\n",
            "predictions =\n",
            " [[0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.709 0.    0.291]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.709 0.    0.291]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]]\n",
            "actual =\n",
            " [[0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7DO6xxXVCym"
      },
      "source": [
        "# Convert the Trained Model to Tensor Flow Lite\n",
        "\n",
        "The next cell converts the model to TFlite format. The size in bytes of the model is also printed out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn1-Rn9Cp_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d53fa6e1-eb31-42f7-8d5b-b98d91ea7a66"
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Model is %d bytes\" % basic_model_size)\n",
        "\n",
        ""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is 22312 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykccQn7SXrUX"
      },
      "source": [
        "## Encode the Model in an Arduino Header File\n",
        "\n",
        "The next cell creates a constant byte array that contains the TFlite model. Import it as a tab with the sketch below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J33uwpNtAku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7013ba-eeef-4b1f-beed-9baa40ea2cce"
      },
      "source": [
        "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
        "!cat gesture_model.tflite | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Header file, model.h, is 137,626 bytes.\n",
            "\n",
            "Open the side panel (refresh if needed). Double click model.h to download the file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eSkHZaLzMId"
      },
      "source": [
        "# Realtime Classification of Sensor Data on Arduino\n",
        "\n",
        "Now it's time to switch back to the tutorial instructions and run our new model on the [Arduino Nano 33 BLE Sense](https://www.arduino.cc/en/Guide/NANO33BLE)"
      ]
    }
  ]
}