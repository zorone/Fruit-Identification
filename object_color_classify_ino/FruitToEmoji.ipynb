{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvDA8AK7QOq-"
      },
      "source": [
        "## Setup Python Environment \n",
        "\n",
        "The next cell sets up the dependencies in required for the notebook, run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y2gs-PL4xDkZ",
        "outputId": "e9f328de-d6a4-479e-adf1-bd85e36573e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "# Setup environment\n",
        "!apt-get -qq install xxd\n",
        "!pip install pandas numpy matplotlib\n",
        "%tensorflow_version 2.x\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lwkeshJk7dg"
      },
      "source": [
        "# Upload Data\n",
        "\n",
        "1. Open the panel on the left side of Colab by clicking on the __>__\n",
        "1. Select the Files tab\n",
        "1. Drag `csv` files from your computer to the tab to upload them into colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSxUeYPNQbOg"
      },
      "source": [
        "# Train Neural Network\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxk414PU3oy3"
      },
      "source": [
        "## Parse and prepare the data\n",
        "\n",
        "The next cell parses the csv files and transforms them to a format that will be used to train the full connected neural network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AGChd1FAk5_j",
        "outputId": "2c638e84-01b5-44ca-b0be-970bf23863dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version = 2.9.2\n",
            "\n",
            "\u001b[32;4mapple\u001b[0m class will be output \u001b[32m0\u001b[0m of the classifier\n",
            "217 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;4mbanana\u001b[0m class will be output \u001b[32m1\u001b[0m of the classifier\n",
            "356 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;4morange\u001b[0m class will be output \u001b[32m2\u001b[0m of the classifier\n",
            "123 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data set parsing and preparation complete.\n",
            "Data set randomization and splitting complete.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import fileinput\n",
        "\n",
        "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
        "\n",
        "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
        "# the same random numbers each time the notebook is run\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "CLASSES = [];\n",
        "\n",
        "for file in os.listdir(\"/content/\"):\n",
        "    if file.endswith(\".csv\"):\n",
        "        CLASSES.append(os.path.splitext(file)[0])\n",
        "\n",
        "CLASSES.sort()\n",
        "\n",
        "SAMPLES_WINDOW_LEN = 1\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "# create a one-hot encoded matrix that is used in the output\n",
        "ONE_HOT_ENCODED_CLASSES = np.eye(NUM_CLASSES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# read each csv file and push an input and output\n",
        "for class_index in range(NUM_CLASSES):\n",
        "  objectClass = CLASSES[class_index]\n",
        "  df = pd.read_csv(\"/content/\" + objectClass + \".csv\")\n",
        "  columns = list(df)\n",
        "  # get rid of pesky empty value lines of csv which cause NaN inputs to TensorFlow\n",
        "  df = df.dropna()\n",
        "  df = df.reset_index(drop=True)\n",
        "   \n",
        "  # calculate the number of objectClass recordings in the file\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_WINDOW_LEN)\n",
        "  print(f\"\\u001b[32;4m{objectClass}\\u001b[0m class will be output \\u001b[32m{class_index}\\u001b[0m of the classifier\")\n",
        "  print(f\"{num_recordings} samples captured for training with inputs {list(df)} \\n\")\n",
        "\n",
        "  # graphing\n",
        "  plt.rcParams[\"figure.figsize\"] = (10,1)\n",
        "  pixels = np.array([df['Red'],df['Green'],df['Blue']],float)\n",
        "  pixels = np.transpose(pixels)\n",
        "  for i in range(num_recordings):\n",
        "    plt.axvline(x=i, linewidth=8, color=tuple(pixels[i]/np.max(pixels[i], axis=0)))\n",
        "  plt.show()\n",
        "  \n",
        "  #tensors\n",
        "  output = ONE_HOT_ENCODED_CLASSES[class_index]\n",
        "  for i in range(num_recordings):\n",
        "    tensor = []\n",
        "    row = []\n",
        "    for c in columns:\n",
        "      row.append(df[c][i])\n",
        "    tensor += row\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "# convert the list to numpy array\n",
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "print(\"Data set parsing and preparation complete.\")\n",
        "\n",
        "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
        "# https://stackoverflow.com/a/37710486/2020087\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "print(\"Data set randomization and splitting complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8qlSAX1b6Yv"
      },
      "source": [
        "## Build & Train the Model\n",
        "\n",
        "Build and train a [TensorFlow](https://www.tensorflow.org) model using the high-level [Keras](https://www.tensorflow.org/guide/keras) API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGNFa-lX24Qo",
        "outputId": "8c773d2d-9b5c-4b84-e6b5-d56c4d13e347"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 0.2143 - mae: 0.4349 - val_loss: 0.2049 - val_mae: 0.4235\n",
            "Epoch 2/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.2003 - mae: 0.4154 - val_loss: 0.1953 - val_mae: 0.4084\n",
            "Epoch 3/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.1931 - mae: 0.4034 - val_loss: 0.1885 - val_mae: 0.3987\n",
            "Epoch 4/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.1861 - mae: 0.3953 - val_loss: 0.1810 - val_mae: 0.3842\n",
            "Epoch 5/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.1789 - mae: 0.3835 - val_loss: 0.1714 - val_mae: 0.3746\n",
            "Epoch 6/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.1698 - mae: 0.3734 - val_loss: 0.1613 - val_mae: 0.3614\n",
            "Epoch 7/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.1599 - mae: 0.3601 - val_loss: 0.1503 - val_mae: 0.3474\n",
            "Epoch 8/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.1482 - mae: 0.3462 - val_loss: 0.1380 - val_mae: 0.3289\n",
            "Epoch 9/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.1357 - mae: 0.3278 - val_loss: 0.1252 - val_mae: 0.3166\n",
            "Epoch 10/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.1221 - mae: 0.3105 - val_loss: 0.1119 - val_mae: 0.2915\n",
            "Epoch 11/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.1080 - mae: 0.2887 - val_loss: 0.0969 - val_mae: 0.2754\n",
            "Epoch 12/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0930 - mae: 0.2667 - val_loss: 0.0834 - val_mae: 0.2544\n",
            "Epoch 13/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0771 - mae: 0.2407 - val_loss: 0.0676 - val_mae: 0.2251\n",
            "Epoch 14/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0624 - mae: 0.2145 - val_loss: 0.0553 - val_mae: 0.2034\n",
            "Epoch 15/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0493 - mae: 0.1888 - val_loss: 0.0427 - val_mae: 0.1725\n",
            "Epoch 16/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0373 - mae: 0.1612 - val_loss: 0.0319 - val_mae: 0.1494\n",
            "Epoch 17/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0278 - mae: 0.1367 - val_loss: 0.0244 - val_mae: 0.1251\n",
            "Epoch 18/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0207 - mae: 0.1152 - val_loss: 0.0183 - val_mae: 0.1054\n",
            "Epoch 19/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0974 - val_loss: 0.0140 - val_mae: 0.0899\n",
            "Epoch 20/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0119 - mae: 0.0817 - val_loss: 0.0105 - val_mae: 0.0759\n",
            "Epoch 21/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0687 - val_loss: 0.0090 - val_mae: 0.0656\n",
            "Epoch 22/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0583 - val_loss: 0.0067 - val_mae: 0.0550\n",
            "Epoch 23/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0504 - val_loss: 0.0056 - val_mae: 0.0481\n",
            "Epoch 24/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0434 - val_loss: 0.0050 - val_mae: 0.0435\n",
            "Epoch 25/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0385 - val_loss: 0.0042 - val_mae: 0.0388\n",
            "Epoch 26/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0340 - val_loss: 0.0037 - val_mae: 0.0350\n",
            "Epoch 27/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0306 - val_loss: 0.0033 - val_mae: 0.0317\n",
            "Epoch 28/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0276 - val_loss: 0.0028 - val_mae: 0.0280\n",
            "Epoch 29/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0250 - val_loss: 0.0024 - val_mae: 0.0253\n",
            "Epoch 30/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0230 - val_loss: 0.0023 - val_mae: 0.0243\n",
            "Epoch 31/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0214 - val_loss: 0.0021 - val_mae: 0.0226\n",
            "Epoch 32/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0200 - val_loss: 0.0019 - val_mae: 0.0212\n",
            "Epoch 33/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0188 - val_loss: 0.0018 - val_mae: 0.0195\n",
            "Epoch 34/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0172 - val_loss: 0.0016 - val_mae: 0.0185\n",
            "Epoch 35/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0163 - val_loss: 0.0017 - val_mae: 0.0193\n",
            "Epoch 36/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0159 - val_loss: 0.0015 - val_mae: 0.0173\n",
            "Epoch 37/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0150 - val_loss: 0.0014 - val_mae: 0.0158\n",
            "Epoch 38/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0139 - val_loss: 0.0013 - val_mae: 0.0144\n",
            "Epoch 39/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0131 - val_loss: 0.0011 - val_mae: 0.0141\n",
            "Epoch 40/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0124 - val_loss: 0.0011 - val_mae: 0.0137\n",
            "Epoch 41/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0121 - val_loss: 0.0010 - val_mae: 0.0128\n",
            "Epoch 42/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0113 - val_loss: 9.3909e-04 - val_mae: 0.0123\n",
            "Epoch 43/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0111 - val_loss: 0.0010 - val_mae: 0.0129\n",
            "Epoch 44/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0109 - val_loss: 9.1586e-04 - val_mae: 0.0122\n",
            "Epoch 45/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0104 - val_loss: 8.4478e-04 - val_mae: 0.0111\n",
            "Epoch 46/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0100 - val_loss: 7.8169e-04 - val_mae: 0.0106\n",
            "Epoch 47/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0094 - val_loss: 7.9565e-04 - val_mae: 0.0102\n",
            "Epoch 48/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0096 - val_loss: 7.6209e-04 - val_mae: 0.0096\n",
            "Epoch 49/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0091 - val_loss: 6.7621e-04 - val_mae: 0.0094\n",
            "Epoch 50/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0086 - val_loss: 6.4942e-04 - val_mae: 0.0094\n",
            "Epoch 51/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0085 - val_loss: 6.1513e-04 - val_mae: 0.0091\n",
            "Epoch 52/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0087 - val_loss: 6.1730e-04 - val_mae: 0.0093\n",
            "Epoch 53/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0079 - val_loss: 6.1326e-04 - val_mae: 0.0093\n",
            "Epoch 54/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0080 - val_loss: 5.2366e-04 - val_mae: 0.0080\n",
            "Epoch 55/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0075 - val_loss: 5.0915e-04 - val_mae: 0.0079\n",
            "Epoch 56/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0073 - val_loss: 4.9380e-04 - val_mae: 0.0079\n",
            "Epoch 57/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0077 - val_loss: 4.9160e-04 - val_mae: 0.0079\n",
            "Epoch 58/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0070 - val_loss: 4.6605e-04 - val_mae: 0.0076\n",
            "Epoch 59/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0068 - val_loss: 4.9588e-04 - val_mae: 0.0080\n",
            "Epoch 60/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0071 - val_loss: 4.6075e-04 - val_mae: 0.0077\n",
            "Epoch 61/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0064 - val_loss: 3.9235e-04 - val_mae: 0.0067\n",
            "Epoch 62/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0062 - val_loss: 4.8815e-04 - val_mae: 0.0077\n",
            "Epoch 63/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0065 - val_loss: 3.6281e-04 - val_mae: 0.0064\n",
            "Epoch 64/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0061 - val_loss: 4.6247e-04 - val_mae: 0.0074\n",
            "Epoch 65/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0059 - val_loss: 3.3935e-04 - val_mae: 0.0062\n",
            "Epoch 66/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0058 - val_loss: 3.6221e-04 - val_mae: 0.0064\n",
            "Epoch 67/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0059 - val_loss: 3.1546e-04 - val_mae: 0.0058\n",
            "Epoch 68/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0057 - val_loss: 3.3992e-04 - val_mae: 0.0062\n",
            "Epoch 69/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0056 - val_loss: 3.2690e-04 - val_mae: 0.0060\n",
            "Epoch 70/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0054 - val_loss: 3.0438e-04 - val_mae: 0.0059\n",
            "Epoch 71/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0051 - val_loss: 3.2415e-04 - val_mae: 0.0060\n",
            "Epoch 72/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0054 - val_loss: 3.2876e-04 - val_mae: 0.0061\n",
            "Epoch 73/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0052 - val_loss: 5.5186e-04 - val_mae: 0.0073\n",
            "Epoch 74/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0055 - val_loss: 2.5800e-04 - val_mae: 0.0053\n",
            "Epoch 75/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0049 - val_loss: 3.5466e-04 - val_mae: 0.0060\n",
            "Epoch 76/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0050 - val_loss: 2.7909e-04 - val_mae: 0.0054\n",
            "Epoch 77/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0049 - val_loss: 2.6380e-04 - val_mae: 0.0052\n",
            "Epoch 78/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0048 - val_loss: 3.0722e-04 - val_mae: 0.0055\n",
            "Epoch 79/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0049 - val_loss: 3.4828e-04 - val_mae: 0.0058\n",
            "Epoch 80/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0052 - val_loss: 2.1282e-04 - val_mae: 0.0046\n",
            "Epoch 81/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0048 - val_loss: 2.4794e-04 - val_mae: 0.0050\n",
            "Epoch 82/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0047 - val_loss: 2.4348e-04 - val_mae: 0.0048\n",
            "Epoch 83/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 2.0906e-04 - val_mae: 0.0045\n",
            "Epoch 84/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 2.5487e-04 - val_mae: 0.0049\n",
            "Epoch 85/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 1.9739e-04 - val_mae: 0.0044\n",
            "Epoch 86/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 2.1037e-04 - val_mae: 0.0045\n",
            "Epoch 87/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 1.6588e-04 - val_mae: 0.0039\n",
            "Epoch 88/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 1.7938e-04 - val_mae: 0.0042\n",
            "Epoch 89/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 1.7013e-04 - val_mae: 0.0041\n",
            "Epoch 90/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 1.8116e-04 - val_mae: 0.0043\n",
            "Epoch 91/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 1.9384e-04 - val_mae: 0.0042\n",
            "Epoch 92/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 1.7741e-04 - val_mae: 0.0041\n",
            "Epoch 93/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 1.5975e-04 - val_mae: 0.0039\n",
            "Epoch 94/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 1.7644e-04 - val_mae: 0.0040\n",
            "Epoch 95/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 2.9580e-04 - val_mae: 0.0049\n",
            "Epoch 96/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 4.5261e-04 - val_mae: 0.0059\n",
            "Epoch 97/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0048 - val_loss: 1.9639e-04 - val_mae: 0.0042\n",
            "Epoch 98/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 1.4853e-04 - val_mae: 0.0037\n",
            "Epoch 99/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 1.9940e-04 - val_mae: 0.0041\n",
            "Epoch 100/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 1.7391e-04 - val_mae: 0.0038\n",
            "Epoch 101/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 1.4866e-04 - val_mae: 0.0036\n",
            "Epoch 102/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 1.3113e-04 - val_mae: 0.0035\n",
            "Epoch 103/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 1.2560e-04 - val_mae: 0.0033\n",
            "Epoch 104/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 1.7912e-04 - val_mae: 0.0038\n",
            "Epoch 105/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 2.0246e-04 - val_mae: 0.0040\n",
            "Epoch 106/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 1.7973e-04 - val_mae: 0.0038\n",
            "Epoch 107/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 2.1674e-04 - val_mae: 0.0040\n",
            "Epoch 108/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 2.1595e-04 - val_mae: 0.0040\n",
            "Epoch 109/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0036 - val_loss: 1.0153e-04 - val_mae: 0.0029\n",
            "Epoch 110/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0036 - val_loss: 1.6023e-04 - val_mae: 0.0034\n",
            "Epoch 111/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0034 - val_loss: 1.2740e-04 - val_mae: 0.0031\n",
            "Epoch 112/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0033 - val_loss: 1.1154e-04 - val_mae: 0.0029\n",
            "Epoch 113/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0035 - val_loss: 1.3874e-04 - val_mae: 0.0032\n",
            "Epoch 114/400\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0033 - val_loss: 8.7710e-05 - val_mae: 0.0027\n",
            "Epoch 115/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0032 - val_loss: 1.3873e-04 - val_mae: 0.0031\n",
            "Epoch 116/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0034 - val_loss: 1.8577e-04 - val_mae: 0.0035\n",
            "Epoch 117/400\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 1.6555e-04 - val_mae: 0.0033\n",
            "Epoch 118/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0035 - val_loss: 1.1455e-04 - val_mae: 0.0029\n",
            "Epoch 119/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0031 - val_loss: 1.0295e-04 - val_mae: 0.0027\n",
            "Epoch 120/400\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0030 - val_loss: 8.7180e-05 - val_mae: 0.0025\n",
            "Epoch 121/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0031 - val_loss: 1.5457e-04 - val_mae: 0.0031\n",
            "Epoch 122/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0031 - val_loss: 1.8639e-04 - val_mae: 0.0033\n",
            "Epoch 123/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0035 - val_loss: 1.6745e-04 - val_mae: 0.0032\n",
            "Epoch 124/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0032 - val_loss: 1.0412e-04 - val_mae: 0.0027\n",
            "Epoch 125/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0030 - val_loss: 1.2023e-04 - val_mae: 0.0028\n",
            "Epoch 126/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0032 - val_loss: 8.6318e-05 - val_mae: 0.0025\n",
            "Epoch 127/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0030 - val_loss: 7.7534e-05 - val_mae: 0.0023\n",
            "Epoch 128/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0030 - val_loss: 1.1644e-04 - val_mae: 0.0027\n",
            "Epoch 129/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0030 - val_loss: 1.1260e-04 - val_mae: 0.0026\n",
            "Epoch 130/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0029 - val_loss: 1.1802e-04 - val_mae: 0.0026\n",
            "Epoch 131/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0031 - val_loss: 9.9029e-05 - val_mae: 0.0024\n",
            "Epoch 132/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0029 - val_loss: 7.4725e-05 - val_mae: 0.0022\n",
            "Epoch 133/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0028 - val_loss: 9.0185e-05 - val_mae: 0.0023\n",
            "Epoch 134/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0028 - val_loss: 1.4600e-04 - val_mae: 0.0027\n",
            "Epoch 135/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0031 - val_loss: 1.2356e-04 - val_mae: 0.0026\n",
            "Epoch 136/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0029 - val_loss: 6.1559e-05 - val_mae: 0.0020\n",
            "Epoch 137/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0028 - val_loss: 7.6795e-05 - val_mae: 0.0022\n",
            "Epoch 138/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0029 - val_loss: 1.0208e-04 - val_mae: 0.0025\n",
            "Epoch 139/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0029 - val_loss: 8.1466e-05 - val_mae: 0.0022\n",
            "Epoch 140/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0029 - val_loss: 8.2991e-05 - val_mae: 0.0022\n",
            "Epoch 141/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0029 - val_loss: 9.2827e-05 - val_mae: 0.0023\n",
            "Epoch 142/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0028 - val_loss: 1.0828e-04 - val_mae: 0.0024\n",
            "Epoch 143/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0029 - val_loss: 8.0807e-05 - val_mae: 0.0021\n",
            "Epoch 144/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0028 - val_loss: 6.0074e-05 - val_mae: 0.0019\n",
            "Epoch 145/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0027 - val_loss: 7.4311e-05 - val_mae: 0.0021\n",
            "Epoch 146/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0027 - val_loss: 5.0629e-05 - val_mae: 0.0018\n",
            "Epoch 147/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0026 - val_loss: 4.5381e-05 - val_mae: 0.0017\n",
            "Epoch 148/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0026 - val_loss: 3.7098e-05 - val_mae: 0.0016\n",
            "Epoch 149/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0026 - val_loss: 5.8895e-05 - val_mae: 0.0018\n",
            "Epoch 150/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0027 - val_loss: 7.3114e-05 - val_mae: 0.0020\n",
            "Epoch 151/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0027 - val_loss: 7.1368e-05 - val_mae: 0.0020\n",
            "Epoch 152/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0027 - val_loss: 6.5553e-05 - val_mae: 0.0019\n",
            "Epoch 153/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0027 - val_loss: 7.1548e-05 - val_mae: 0.0020\n",
            "Epoch 154/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0027 - val_loss: 9.6193e-05 - val_mae: 0.0022\n",
            "Epoch 155/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0026 - val_loss: 7.5520e-05 - val_mae: 0.0020\n",
            "Epoch 156/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0028 - val_loss: 6.1007e-05 - val_mae: 0.0018\n",
            "Epoch 157/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0028 - val_loss: 1.1639e-04 - val_mae: 0.0023\n",
            "Epoch 158/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0026 - val_loss: 1.2925e-04 - val_mae: 0.0024\n",
            "Epoch 159/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0027 - val_loss: 1.5897e-04 - val_mae: 0.0025\n",
            "Epoch 160/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0027 - val_loss: 6.1203e-05 - val_mae: 0.0018\n",
            "Epoch 161/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0026 - val_loss: 1.2653e-04 - val_mae: 0.0023\n",
            "Epoch 162/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0028 - val_loss: 8.7726e-05 - val_mae: 0.0021\n",
            "Epoch 163/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0028 - val_loss: 5.9581e-05 - val_mae: 0.0018\n",
            "Epoch 164/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0027 - val_loss: 6.2173e-05 - val_mae: 0.0018\n",
            "Epoch 165/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0025 - val_loss: 8.5959e-05 - val_mae: 0.0019\n",
            "Epoch 166/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0025 - val_loss: 9.3122e-05 - val_mae: 0.0020\n",
            "Epoch 167/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0026 - val_loss: 9.4955e-05 - val_mae: 0.0021\n",
            "Epoch 168/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0027 - val_loss: 1.0957e-04 - val_mae: 0.0022\n",
            "Epoch 169/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0026 - val_loss: 7.5466e-05 - val_mae: 0.0019\n",
            "Epoch 170/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0026 - val_loss: 1.0676e-04 - val_mae: 0.0021\n",
            "Epoch 171/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0026 - val_loss: 7.6774e-05 - val_mae: 0.0019\n",
            "Epoch 172/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0026 - val_loss: 1.1956e-04 - val_mae: 0.0022\n",
            "Epoch 173/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0027 - val_loss: 1.3080e-04 - val_mae: 0.0022\n",
            "Epoch 174/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0024 - val_loss: 6.1014e-05 - val_mae: 0.0016\n",
            "Epoch 175/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0024 - val_loss: 8.1862e-05 - val_mae: 0.0018\n",
            "Epoch 176/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0024 - val_loss: 1.3600e-04 - val_mae: 0.0022\n",
            "Epoch 177/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0025 - val_loss: 8.6093e-05 - val_mae: 0.0019\n",
            "Epoch 178/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0025 - val_loss: 1.0458e-04 - val_mae: 0.0020\n",
            "Epoch 179/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0025 - val_loss: 5.5786e-05 - val_mae: 0.0016\n",
            "Epoch 180/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0025 - val_loss: 5.6324e-05 - val_mae: 0.0016\n",
            "Epoch 181/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0025 - val_loss: 1.5768e-04 - val_mae: 0.0023\n",
            "Epoch 182/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0025 - val_loss: 1.3881e-04 - val_mae: 0.0022\n",
            "Epoch 183/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0024 - val_loss: 7.1235e-05 - val_mae: 0.0017\n",
            "Epoch 184/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0024 - val_loss: 4.0930e-05 - val_mae: 0.0014\n",
            "Epoch 185/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0024 - val_loss: 5.5831e-05 - val_mae: 0.0015\n",
            "Epoch 186/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0023 - val_loss: 5.3758e-05 - val_mae: 0.0015\n",
            "Epoch 187/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0024 - val_loss: 6.6504e-05 - val_mae: 0.0016\n",
            "Epoch 188/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0024 - val_loss: 7.5207e-05 - val_mae: 0.0017\n",
            "Epoch 189/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0023 - val_loss: 4.0110e-05 - val_mae: 0.0014\n",
            "Epoch 190/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0024 - val_loss: 5.0813e-05 - val_mae: 0.0015\n",
            "Epoch 191/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0023 - val_loss: 3.5792e-05 - val_mae: 0.0014\n",
            "Epoch 192/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0023 - val_loss: 8.2905e-05 - val_mae: 0.0018\n",
            "Epoch 193/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0025 - val_loss: 8.5751e-05 - val_mae: 0.0018\n",
            "Epoch 194/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0024 - val_loss: 1.1137e-04 - val_mae: 0.0020\n",
            "Epoch 195/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0026 - val_loss: 1.2632e-04 - val_mae: 0.0021\n",
            "Epoch 196/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0024 - val_loss: 5.5464e-05 - val_mae: 0.0015\n",
            "Epoch 197/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0023 - val_loss: 9.1599e-05 - val_mae: 0.0018\n",
            "Epoch 198/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0023 - val_loss: 6.6679e-05 - val_mae: 0.0016\n",
            "Epoch 199/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 8.9550e-05 - val_mae: 0.0017\n",
            "Epoch 200/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0023 - val_loss: 4.1754e-05 - val_mae: 0.0013\n",
            "Epoch 201/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 1.0914e-04 - val_mae: 0.0018\n",
            "Epoch 202/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0023 - val_loss: 5.1812e-05 - val_mae: 0.0014\n",
            "Epoch 203/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 4.6550e-05 - val_mae: 0.0014\n",
            "Epoch 204/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0023 - val_loss: 5.6587e-05 - val_mae: 0.0014\n",
            "Epoch 205/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 8.9103e-05 - val_mae: 0.0016\n",
            "Epoch 206/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0024 - val_loss: 9.6786e-05 - val_mae: 0.0017\n",
            "Epoch 207/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 5.9897e-05 - val_mae: 0.0014\n",
            "Epoch 208/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 6.7165e-05 - val_mae: 0.0015\n",
            "Epoch 209/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 7.0016e-05 - val_mae: 0.0015\n",
            "Epoch 210/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 6.9198e-05 - val_mae: 0.0015\n",
            "Epoch 211/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 7.8537e-05 - val_mae: 0.0016\n",
            "Epoch 212/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 6.1292e-05 - val_mae: 0.0014\n",
            "Epoch 213/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 7.4764e-05 - val_mae: 0.0016\n",
            "Epoch 214/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 4.2999e-05 - val_mae: 0.0013\n",
            "Epoch 215/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 4.5099e-05 - val_mae: 0.0013\n",
            "Epoch 216/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 6.3958e-05 - val_mae: 0.0015\n",
            "Epoch 217/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 7.7919e-05 - val_mae: 0.0015\n",
            "Epoch 218/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 1.1562e-04 - val_mae: 0.0017\n",
            "Epoch 219/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 1.1240e-04 - val_mae: 0.0017\n",
            "Epoch 220/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 9.4777e-05 - val_mae: 0.0016\n",
            "Epoch 221/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 1.0780e-04 - val_mae: 0.0017\n",
            "Epoch 222/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 6.5124e-05 - val_mae: 0.0014\n",
            "Epoch 223/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 1.0520e-04 - val_mae: 0.0017\n",
            "Epoch 224/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 8.8242e-05 - val_mae: 0.0016\n",
            "Epoch 225/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 8.4239e-05 - val_mae: 0.0016\n",
            "Epoch 226/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 6.0943e-05 - val_mae: 0.0014\n",
            "Epoch 227/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 6.1118e-05 - val_mae: 0.0014\n",
            "Epoch 228/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 5.8329e-05 - val_mae: 0.0014\n",
            "Epoch 229/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 6.7450e-05 - val_mae: 0.0014\n",
            "Epoch 230/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 5.6053e-05 - val_mae: 0.0013\n",
            "Epoch 231/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 7.7956e-05 - val_mae: 0.0015\n",
            "Epoch 232/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 7.9927e-05 - val_mae: 0.0015\n",
            "Epoch 233/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 6.5782e-05 - val_mae: 0.0014\n",
            "Epoch 234/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 8.0824e-05 - val_mae: 0.0015\n",
            "Epoch 235/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 1.2764e-04 - val_mae: 0.0018\n",
            "Epoch 236/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 7.8436e-05 - val_mae: 0.0015\n",
            "Epoch 237/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 9.0847e-05 - val_mae: 0.0016\n",
            "Epoch 238/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0023 - val_loss: 1.2683e-04 - val_mae: 0.0018\n",
            "Epoch 239/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 1.4397e-04 - val_mae: 0.0018\n",
            "Epoch 240/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0023 - val_loss: 2.1719e-04 - val_mae: 0.0021\n",
            "Epoch 241/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0022 - val_loss: 2.4477e-04 - val_mae: 0.0022\n",
            "Epoch 242/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0024 - val_loss: 4.2473e-04 - val_mae: 0.0029\n",
            "Epoch 243/400\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0024 - val_loss: 5.3000e-04 - val_mae: 0.0032\n",
            "Epoch 244/400\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0012 - mae: 0.0024 - val_loss: 3.8397e-04 - val_mae: 0.0028\n",
            "Epoch 245/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0023 - val_loss: 3.0410e-04 - val_mae: 0.0025\n",
            "Epoch 246/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0024 - val_loss: 2.6442e-04 - val_mae: 0.0024\n",
            "Epoch 247/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0024 - val_loss: 3.7098e-04 - val_mae: 0.0027\n",
            "Epoch 248/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0024 - val_loss: 2.0641e-04 - val_mae: 0.0021\n",
            "Epoch 249/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 1.3556e-04 - val_mae: 0.0018\n",
            "Epoch 250/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0022 - val_loss: 2.0431e-04 - val_mae: 0.0021\n",
            "Epoch 251/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0023 - val_loss: 1.4132e-04 - val_mae: 0.0018\n",
            "Epoch 252/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 1.2830e-04 - val_mae: 0.0018\n",
            "Epoch 253/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 7.4515e-05 - val_mae: 0.0015\n",
            "Epoch 254/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 7.0364e-05 - val_mae: 0.0015\n",
            "Epoch 255/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0023 - val_loss: 7.2889e-05 - val_mae: 0.0015\n",
            "Epoch 256/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 1.1488e-04 - val_mae: 0.0017\n",
            "Epoch 257/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 7.3423e-05 - val_mae: 0.0015\n",
            "Epoch 258/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0022 - val_loss: 1.4683e-04 - val_mae: 0.0019\n",
            "Epoch 259/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0023 - val_loss: 2.4848e-04 - val_mae: 0.0022\n",
            "Epoch 260/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 1.9880e-04 - val_mae: 0.0019\n",
            "Epoch 261/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0023 - val_loss: 2.9806e-04 - val_mae: 0.0023\n",
            "Epoch 262/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0023 - val_loss: 3.0352e-04 - val_mae: 0.0024\n",
            "Epoch 263/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 9.4335e-05 - val_mae: 0.0015\n",
            "Epoch 264/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0021 - val_loss: 1.7354e-04 - val_mae: 0.0019\n",
            "Epoch 265/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0021 - val_loss: 1.6573e-04 - val_mae: 0.0018\n",
            "Epoch 266/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 2.2102e-04 - val_mae: 0.0020\n",
            "Epoch 267/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0022 - val_loss: 1.9167e-04 - val_mae: 0.0019\n",
            "Epoch 268/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0022 - val_loss: 2.5921e-04 - val_mae: 0.0022\n",
            "Epoch 269/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0021 - val_loss: 1.0083e-04 - val_mae: 0.0015\n",
            "Epoch 270/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 1.9086e-04 - val_mae: 0.0019\n",
            "Epoch 271/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0021 - val_loss: 1.2007e-04 - val_mae: 0.0016\n",
            "Epoch 272/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 1.7779e-04 - val_mae: 0.0019\n",
            "Epoch 273/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0022 - val_loss: 1.6420e-04 - val_mae: 0.0018\n",
            "Epoch 274/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0021 - val_loss: 1.7136e-04 - val_mae: 0.0019\n",
            "Epoch 275/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0021 - val_loss: 1.6290e-04 - val_mae: 0.0018\n",
            "Epoch 276/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0021 - val_loss: 1.3546e-04 - val_mae: 0.0017\n",
            "Epoch 277/400\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0021 - val_loss: 1.1673e-04 - val_mae: 0.0016\n",
            "Epoch 278/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0021 - val_loss: 1.4206e-04 - val_mae: 0.0016\n",
            "Epoch 279/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0020 - val_loss: 1.0831e-04 - val_mae: 0.0014\n",
            "Epoch 280/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 2.2045e-04 - val_mae: 0.0019\n",
            "Epoch 281/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0020 - val_loss: 2.4040e-04 - val_mae: 0.0020\n",
            "Epoch 282/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0021 - val_loss: 4.4892e-04 - val_mae: 0.0027\n",
            "Epoch 283/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0023 - val_loss: 3.3032e-04 - val_mae: 0.0023\n",
            "Epoch 284/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0022 - val_loss: 2.4390e-04 - val_mae: 0.0020\n",
            "Epoch 285/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 2.3163e-04 - val_mae: 0.0020\n",
            "Epoch 286/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0022 - val_loss: 1.5651e-04 - val_mae: 0.0017\n",
            "Epoch 287/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0021 - val_loss: 1.3748e-04 - val_mae: 0.0016\n",
            "Epoch 288/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 2.6930e-04 - val_mae: 0.0021\n",
            "Epoch 289/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 2.1560e-04 - val_mae: 0.0020\n",
            "Epoch 290/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0021 - val_loss: 2.2506e-04 - val_mae: 0.0019\n",
            "Epoch 291/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 3.6716e-04 - val_mae: 0.0024\n",
            "Epoch 292/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0022 - val_loss: 2.9825e-04 - val_mae: 0.0022\n",
            "Epoch 293/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 2.1749e-04 - val_mae: 0.0019\n",
            "Epoch 294/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 2.3484e-04 - val_mae: 0.0020\n",
            "Epoch 295/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 2.7340e-04 - val_mae: 0.0021\n",
            "Epoch 296/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0021 - val_loss: 3.1558e-04 - val_mae: 0.0023\n",
            "Epoch 297/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0021 - val_loss: 3.6854e-04 - val_mae: 0.0024\n",
            "Epoch 298/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0020 - val_loss: 8.9087e-05 - val_mae: 0.0013\n",
            "Epoch 299/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 1.1493e-04 - val_mae: 0.0014\n",
            "Epoch 300/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0019 - val_loss: 8.6875e-05 - val_mae: 0.0012\n",
            "Epoch 301/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 1.8119e-04 - val_mae: 0.0017\n",
            "Epoch 302/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 3.0463e-04 - val_mae: 0.0021\n",
            "Epoch 303/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 2.9622e-04 - val_mae: 0.0021\n",
            "Epoch 304/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0021 - val_loss: 3.5115e-04 - val_mae: 0.0023\n",
            "Epoch 305/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 2.6184e-04 - val_mae: 0.0020\n",
            "Epoch 306/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0021 - val_loss: 3.4433e-04 - val_mae: 0.0023\n",
            "Epoch 307/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0021 - val_loss: 1.8072e-04 - val_mae: 0.0017\n",
            "Epoch 308/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 2.6271e-04 - val_mae: 0.0020\n",
            "Epoch 309/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0020 - val_loss: 2.3340e-04 - val_mae: 0.0018\n",
            "Epoch 310/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0020 - val_loss: 1.0209e-04 - val_mae: 0.0013\n",
            "Epoch 311/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 2.1002e-04 - val_mae: 0.0018\n",
            "Epoch 312/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 2.3157e-04 - val_mae: 0.0019\n",
            "Epoch 313/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0020 - val_loss: 1.7775e-04 - val_mae: 0.0017\n",
            "Epoch 314/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 3.3528e-04 - val_mae: 0.0022\n",
            "Epoch 315/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0020 - val_loss: 5.3487e-04 - val_mae: 0.0027\n",
            "Epoch 316/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0020 - val_loss: 1.8638e-04 - val_mae: 0.0017\n",
            "Epoch 317/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 3.6163e-04 - val_mae: 0.0023\n",
            "Epoch 318/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 4.6246e-04 - val_mae: 0.0025\n",
            "Epoch 319/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 3.9173e-04 - val_mae: 0.0023\n",
            "Epoch 320/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 4.7266e-04 - val_mae: 0.0026\n",
            "Epoch 321/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 9.3566e-04 - mae: 0.0020 - val_loss: 4.7076e-04 - val_mae: 0.0025\n",
            "Epoch 322/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0020 - val_loss: 8.7807e-05 - val_mae: 0.0012\n",
            "Epoch 323/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 1.2429e-04 - val_mae: 0.0014\n",
            "Epoch 324/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 1.4392e-04 - val_mae: 0.0015\n",
            "Epoch 325/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0019 - val_loss: 6.2267e-05 - val_mae: 0.0010\n",
            "Epoch 326/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 1.3164e-04 - val_mae: 0.0014\n",
            "Epoch 327/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0019 - val_loss: 7.7024e-05 - val_mae: 0.0011\n",
            "Epoch 328/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 1.1865e-04 - val_mae: 0.0013\n",
            "Epoch 329/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 1.9770e-04 - val_mae: 0.0017\n",
            "Epoch 330/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 1.6497e-04 - val_mae: 0.0016\n",
            "Epoch 331/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 2.0265e-04 - val_mae: 0.0017\n",
            "Epoch 332/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 1.5510e-04 - val_mae: 0.0015\n",
            "Epoch 333/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 2.1948e-04 - val_mae: 0.0018\n",
            "Epoch 334/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 2.2775e-04 - val_mae: 0.0018\n",
            "Epoch 335/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 1.9281e-04 - val_mae: 0.0016\n",
            "Epoch 336/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 3.2270e-04 - val_mae: 0.0021\n",
            "Epoch 337/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 6.8199e-04 - val_mae: 0.0029\n",
            "Epoch 338/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0020 - val_loss: 2.0415e-04 - val_mae: 0.0017\n",
            "Epoch 339/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 3.0214e-04 - val_mae: 0.0020\n",
            "Epoch 340/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0020 - val_loss: 2.3807e-04 - val_mae: 0.0018\n",
            "Epoch 341/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 2.1327e-04 - val_mae: 0.0017\n",
            "Epoch 342/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 3.8593e-04 - val_mae: 0.0022\n",
            "Epoch 343/400\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0020 - val_loss: 4.2524e-04 - val_mae: 0.0024\n",
            "Epoch 344/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 1.0677e-04 - val_mae: 0.0013\n",
            "Epoch 345/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 1.9521e-04 - val_mae: 0.0016\n",
            "Epoch 346/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 1.9238e-04 - val_mae: 0.0016\n",
            "Epoch 347/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 1.8074e-04 - val_mae: 0.0016\n",
            "Epoch 348/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 9.9000e-05 - val_mae: 0.0012\n",
            "Epoch 349/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0018 - val_loss: 1.5149e-04 - val_mae: 0.0014\n",
            "Epoch 350/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 2.3825e-04 - val_mae: 0.0018\n",
            "Epoch 351/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0019 - val_loss: 8.6647e-05 - val_mae: 0.0011\n",
            "Epoch 352/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 1.0957e-04 - val_mae: 0.0012\n",
            "Epoch 353/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0018 - val_loss: 4.1168e-05 - val_mae: 8.5739e-04\n",
            "Epoch 354/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 9.5106e-05 - val_mae: 0.0012\n",
            "Epoch 355/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 1.3799e-04 - val_mae: 0.0014\n",
            "Epoch 356/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0018 - val_loss: 8.1921e-05 - val_mae: 0.0011\n",
            "Epoch 357/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 1.3786e-04 - val_mae: 0.0014\n",
            "Epoch 358/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0019 - val_loss: 4.8128e-05 - val_mae: 9.1408e-04\n",
            "Epoch 359/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0018 - val_loss: 4.7962e-05 - val_mae: 9.2382e-04\n",
            "Epoch 360/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0018 - val_loss: 9.0786e-05 - val_mae: 0.0012\n",
            "Epoch 361/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 1.8426e-04 - val_mae: 0.0015\n",
            "Epoch 362/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 1.5900e-04 - val_mae: 0.0014\n",
            "Epoch 363/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 1.7677e-04 - val_mae: 0.0015\n",
            "Epoch 364/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0018 - val_loss: 1.6081e-04 - val_mae: 0.0014\n",
            "Epoch 365/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0018 - val_loss: 2.0552e-04 - val_mae: 0.0016\n",
            "Epoch 366/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0018 - val_loss: 1.8194e-04 - val_mae: 0.0015\n",
            "Epoch 367/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0018 - val_loss: 3.8588e-04 - val_mae: 0.0021\n",
            "Epoch 368/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 6.8756e-04 - val_mae: 0.0028\n",
            "Epoch 369/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 9.3427e-04 - mae: 0.0019 - val_loss: 8.4030e-04 - val_mae: 0.0032\n",
            "Epoch 370/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 9.9307e-04 - mae: 0.0019 - val_loss: 5.4136e-04 - val_mae: 0.0025\n",
            "Epoch 371/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 9.3100e-04 - mae: 0.0019 - val_loss: 7.6003e-04 - val_mae: 0.0030\n",
            "Epoch 372/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 3.8716e-04 - val_mae: 0.0021\n",
            "Epoch 373/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 4.8846e-04 - val_mae: 0.0023\n",
            "Epoch 374/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 3.7493e-04 - val_mae: 0.0020\n",
            "Epoch 375/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 5.2442e-04 - val_mae: 0.0024\n",
            "Epoch 376/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 9.7178e-04 - mae: 0.0019 - val_loss: 4.7838e-04 - val_mae: 0.0023\n",
            "Epoch 377/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0019 - val_loss: 4.6696e-04 - val_mae: 0.0023\n",
            "Epoch 378/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 4.4593e-04 - val_mae: 0.0023\n",
            "Epoch 379/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 9.6814e-04 - mae: 0.0019 - val_loss: 5.3684e-04 - val_mae: 0.0024\n",
            "Epoch 380/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 5.2962e-04 - val_mae: 0.0024\n",
            "Epoch 381/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 3.8222e-04 - val_mae: 0.0020\n",
            "Epoch 382/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0018 - val_loss: 6.6322e-04 - val_mae: 0.0027\n",
            "Epoch 383/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0018 - val_loss: 2.3026e-04 - val_mae: 0.0016\n",
            "Epoch 384/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 4.6739e-04 - val_mae: 0.0023\n",
            "Epoch 385/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0018 - val_loss: 6.4559e-04 - val_mae: 0.0027\n",
            "Epoch 386/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 8.4000e-04 - mae: 0.0018 - val_loss: 4.9035e-04 - val_mae: 0.0023\n",
            "Epoch 387/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 3.2374e-04 - val_mae: 0.0019\n",
            "Epoch 388/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0018 - val_loss: 3.2475e-04 - val_mae: 0.0019\n",
            "Epoch 389/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 4.5933e-04 - val_mae: 0.0022\n",
            "Epoch 390/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0019 - val_loss: 5.2545e-04 - val_mae: 0.0024\n",
            "Epoch 391/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0018 - val_loss: 1.8947e-04 - val_mae: 0.0015\n",
            "Epoch 392/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0018 - val_loss: 2.6961e-04 - val_mae: 0.0017\n",
            "Epoch 393/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0018 - val_loss: 3.7882e-04 - val_mae: 0.0020\n",
            "Epoch 394/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0018 - val_loss: 3.6403e-04 - val_mae: 0.0020\n",
            "Epoch 395/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0019 - val_loss: 4.0138e-04 - val_mae: 0.0021\n",
            "Epoch 396/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0018 - val_loss: 4.9567e-04 - val_mae: 0.0023\n",
            "Epoch 397/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0018 - val_loss: 3.0251e-04 - val_mae: 0.0018\n",
            "Epoch 398/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0018 - val_loss: 1.7619e-04 - val_mae: 0.0014\n",
            "Epoch 399/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0017 - val_loss: 3.5250e-04 - val_mae: 0.0020\n",
            "Epoch 400/400\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0018 - val_loss: 5.4919e-04 - val_mae: 0.0024\n"
          ]
        }
      ],
      "source": [
        "# build the model and train it\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu')) # relu is used for performance\n",
        "model.add(tf.keras.layers.Dense(ุ6, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(6, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')) # softmax is used, because we only expect one class to occur per input\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "history = model.fit(inputs_train, outputs_train, epochs=400, batch_size=4, validation_data=(inputs_validate, outputs_validate))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guMjtfa42ahM"
      },
      "source": [
        "### Run with Test Data\n",
        "Put our test data into the model and plot the predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V3Y0CCWJz2EK",
        "outputId": "e09dee93-92d3-4af8-fdb3-2cf21c5f62b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step\n",
            "predictions =\n",
            " [[1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.287 0.713 0.   ]\n",
            " [0.999 0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [0.001 0.    0.999]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.002 0.    0.998]\n",
            " [1.    0.    0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.002 0.    0.998]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.003 0.    0.997]\n",
            " [0.002 0.    0.998]\n",
            " [0.995 0.002 0.003]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.003 0.    0.997]\n",
            " [0.003 0.997 0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.998 0.001 0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [0.001 0.    0.999]\n",
            " [1.    0.    0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [0.002 0.    0.998]\n",
            " [0.001 0.    0.999]\n",
            " [0.002 0.    0.998]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [0.    1.    0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [1.    0.    0.   ]\n",
            " [0.003 0.997 0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.001 0.    0.999]]\n",
            "actual =\n",
            " [[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# use the model to predict the test inputs\n",
        "predictions = model.predict(inputs_test)\n",
        "\n",
        "# print the predictions and the expected ouputs\n",
        "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
        "print(\"actual =\\n\", outputs_test)\n",
        "\n",
        "# Plot the predictions along with to the test data\n",
        "plt.clf()\n",
        "plt.title('Training data predicted vs actual values')\n",
        "plt.plot(inputs_test, outputs_test, 'b.', label='Actual')\n",
        "plt.plot(inputs_test, predictions, 'r.', label='Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7DO6xxXVCym"
      },
      "source": [
        "# Convert the Trained Model to Tensor Flow Lite\n",
        "\n",
        "The next cell converts the model to TFlite format. The size in bytes of the model is also printed out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xn1-Rn9Cp_8",
        "outputId": "ded7fa14-99ae-487d-d98c-b7cc829d3b2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is 2464 bytes\n"
          ]
        }
      ],
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "  \n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Model is %d bytes\" % basic_model_size)\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykccQn7SXrUX"
      },
      "source": [
        "## Encode the Model in an Arduino Header File \n",
        "\n",
        "The next cell creates a constant byte array that contains the TFlite model. Import it as a tab with the sketch below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J33uwpNtAku",
        "outputId": "5dfff3bb-b891-4acf-a4fe-312c77dbf25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Header file, model.h, is 15,230 bytes.\n",
            "\n",
            "Open the side panel (refresh if needed). Double click model.h to download the file.\n"
          ]
        }
      ],
      "source": [
        "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
        "!cat gesture_model.tflite | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eSkHZaLzMId"
      },
      "source": [
        "# Realtime Classification of Sensor Data on Arduino\n",
        "\n",
        "Now it's time to switch back to the tutorial instructions and run our new model on the [Arduino Nano 33 BLE Sense](https://www.arduino.cc/en/Guide/NANO33BLE)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}